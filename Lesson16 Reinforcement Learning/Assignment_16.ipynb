{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.复习上课内容。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.理论题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Why we need $\\gamma$ in reinforcement learning ?"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ans: $\\gamma$ 折扣率，其一是因为当前的奖励对于当前的状态下执行的动作比起过去的或未来的奖励更重要，$\\gamma$可以按时间来使过去或未来的\n",
    "奖励对模型的重要性有所衰减。其二是若没有$\\gamma$， 可能会导致状态无限循环。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Please breifly explain what is value function and what is Q function ?"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ans: 价值函数包含状态价值函数和动作价值函数（Q 函数）。\n",
    "\n",
    "* 状态价值函数： $v(s) = E[U_t | S_t = s] $  \n",
    "表示t时刻状态s能得到的未来回报的期望值。\n",
    "\n",
    "* 动作价值函数： $q_\\pi =  E_\\pi[U_t | S_t = s, A_t = a]$  \n",
    "表示t时刻状态s并选择一个动作a后能获得未来的回报的期望值。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. How temperal difference related to dynamic programming and monte-carlo methods ?"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ans: 动态规划和蒙特卡洛方法最大的不同在于是否已知环境的状态转换概率。若已知环境的状态转换概率则可以使用动态规划迭代找出最优解。若未知环境状态转换\n",
    "概率则需要不断地做实验采样，保证每种状态-动作的可能都被采样到，并利用采样得到的结果去平均去估计状态的期望值函数，也就是蒙特卡洛方法。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Please briefly describe what are value iteration and policy iteration ?"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ans:\n",
    "价值迭代：对每一个当前状态 s ,对每个可能的动作 a 都计算一下采取这个动作后到达的下一个状态的期望价值。看看哪个动作可以到达的状态的期望价值\n",
    "函数最大，就将这个最大的期望价值函数作为当前状态的价值函数$ V(s) $循环执行这个步骤，直到价值函数收敛。\n",
    "\n",
    "策略迭代：从一个初始化的策略出发，先进行策略评估，然后改进策略，评估改进的策略，再进一步改进策略，经过不断迭代更新，直达策略收敛。\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. How can we use deep lerning in reinforcement learning ?"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ans:\n",
    "使用深度学习方法构建一个网络模型，环境状态State作为模型的输入，中间可能会有一些CNN RNN等结构，然后输出对应着当前环境状态要做的动作。\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 选做题 （实践）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.table import Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def draw_image(image):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_axis_off()\n",
    "    tb = Table(ax, bbox=[0,0,1,1])\n",
    "\n",
    "    nrows, ncols = image.shape\n",
    "    width, height = 1.0/ncols,1.0/nrows\n",
    "\n",
    "    for (i,j), val in np.ndenumerate(image):\n",
    "        if (i,j) == (0,1):\n",
    "            val = \"A\"\n",
    "        elif (i,j) == (0,3):\n",
    "            val = \"B\"\n",
    "        elif (i,j) == (4,1):\n",
    "            val = \"A'\"\n",
    "        elif (i,j) == (2,3):\n",
    "            val = \"B'\"\n",
    "        tb.add_cell(i, j, width, height, text=val,\n",
    "                    loc='center', facecolor='white')\n",
    "\n",
    "    for i in range(len(image)):\n",
    "        tb.add_cell(i, -1, width, height, text=i+1, loc='right',\n",
    "                    edgecolor='none', facecolor='none')\n",
    "        tb.add_cell(-1, i, width, height/2, text=i+1, loc='center',\n",
    "                    edgecolor='none', facecolor='none')\n",
    "    ax.add_table(tb)\n",
    "\n",
    "##%%\n",
    "\n",
    "WORLD_SIZE=5\n",
    "draw_image(np.zeros((WORLD_SIZE, WORLD_SIZE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure above shows a rectangular gridworld. The cell of the grid correspond to the state of the environment.\n",
    "At each cell, four actions with equal probability are possible: north, south, east and west,\n",
    "which deterministically cause the agent to move one cell in the respective direction on the grid.\n",
    "Actions that would take the agent off the grid leave its unchanged, but also result in a reward -1.\n",
    "Other actions result in a reward of 0, expect those taht move the agent out of the special states A and B.\n",
    "From state A, all four actions yield a reward of +10 and take the agent to A'.\n",
    " From state B, all actions yield a reward of +5 and take the agent to B'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try to compute the value of each state ? You can choose any algorithms we leanred in the class.\n",
    "Good luck and happy new year. !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}