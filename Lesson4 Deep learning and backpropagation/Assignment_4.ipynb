{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 复习上课内容以及复现课程代码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在本部分，你需要复习上课内容和课程代码后，自己复现课程代码。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 回答一下理论题目"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. What does a neuron compute?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: 神经元计算，模仿生物神经元的生物机理，简化出一种计算模型，接收多个输入，对每个输入乘上一个权重值，加上一个偏移量 ，然后在输出上加个激活函数，这样的计算过程便是神经元计算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  2. Why we use non-linear activation funcitons in neural networks?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans： 一方面是因为没有非线性激活函数的神经网络输出的值只能是线性的，而现实中很多情况是非线性的，在神经网络中加入非线性激活函数才更好地拟合现实中非线性的情况。\n",
    "    另一方面多层神经网络中，层与层之间若没有非线性激活函数相连，那么多层神经网络可以简化为一层。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. What is the 'Logistic Loss' ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: 逻辑回归模型使用的Loss函数为Logistic Loss函数\n",
    "\n",
    "$$ LogisticLoss = - y log \\hat y - (1 - y)log(1 - \\hat y)  $$\n",
    "\n",
    "$$ \\hat y 是模型预测值， y是真实值 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Assume that you are building a binary classifier for detecting if an image containing cats, which activation functions would you recommen using for the output layer ?\n",
    "\n",
    "A. ReLU    \n",
    "B. Leaky ReLU    \n",
    "C. sigmoid    \n",
    "D. tanh  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: 二分类输出概率，选择C sigmoid "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Why we don't use zero initialization for all parameters ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans： 对于WX + b，对W矩阵的初始化不使用全0来初始化，是因为全0会导致所有的梯度下降反向传递后各个分支的W值完全相同，然后难以收敛到一个期望的状态。对于b来说则无所谓，全0初始化也没关系。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Can you implement the softmax function using python ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "softmax 函数输入输出都是至少是个一维向量，并且输入向量和输出向量的维度是相等的。\n",
    "其中输入向量Z ,输出Y，z和y为Z和Y中的元素\n",
    "\n",
    "##  $$ y_n = \\frac {  e^{z_n}  }{  \\sum_{j=1}^m {e^{z_j}}  } $$\n",
    "\n",
    "n ： 当前的第n个元素\n",
    "\n",
    "m ： 输入的元素个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.011656230956039609, 0.03168492079612427, 0.0861285444362687, 0.23412165725273662, 0.6364086465588308]\n",
      "1.0\n",
      "[0.011655894183363012, 0.03168400535307716, 0.08612605600406874, 0.2341148929927061, 0.6363902593937069, 2.889207307800382e-05]\n",
      "0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def softmax(Z:[]):\n",
    "    sumValue = sum([math.e ** z for z in Z])\n",
    "    return [math.e ** z / sumValue for z in Z]\n",
    "\n",
    "print(softmax([1,2,3,4,5]))\n",
    "print(sum(softmax([1,2,3,4,5])))\n",
    "print(softmax([1,2,3,4,5, -5]))\n",
    "print(sum(softmax([1,2,3,4,5, -5])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.实践题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this practical part, you will build a simple digits recognizer to check if the digit in the image is larger than 5. This assignmnet will guide you step by step to finish your first small project in this course ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 - Packages  \n",
    "sklearn is a famous package for machine learning.   \n",
    "matplotlib is a common package for vasualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 - Overvie of the dataset  \n",
    "    - a training set has m_train images labeled as 0 if the digit < 5 or 1 if the digit >= 5\n",
    "    - a test set contains m_test images labels as if the digit < 5 or 1 if the digit >= 5\n",
    "    - eah image if of shape (num_px, num_px ). Thus, each image is square(height=num_px and  width = num_px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1797\n",
      "[ 0.  0.  5. 13.  9.  1.  0.  0.  0.  0. 13. 15. 10. 15.  5.  0.  0.  3.\n",
      " 15.  2.  0. 11.  8.  0.  0.  4. 12.  0.  0.  8.  8.  0.  0.  5.  8.  0.\n",
      "  0.  9.  8.  0.  0.  4. 11.  0.  1. 12.  7.  0.  0.  2. 14.  5. 10. 12.\n",
      "  0.  0.  0.  0.  6. 13. 10.  0.  0.  0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x156ff05c848>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loading the data \n",
    "digits = datasets.load_digits()\n",
    "print(len(digits.data))\n",
    "print(digits.data[0])\n",
    "plt.imshow(digits.data[0].reshape([8,8]),cmap=plt.cm.gray_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 100 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Vilizating the data\n",
    "count = 100\n",
    "for i in range(0, count):\n",
    "    plt.subplot(count / 10, 10,i+1)\n",
    "    plt.imshow(digits.data[i].reshape([8,8]),cmap=plt.cm.gray_r)\n",
    "    plt.text(3,10,str(digits.target[i]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1347\n",
      "450\n",
      "1347\n",
      "450\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training set and test set \n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.25)\n",
    "\n",
    "print(len(X_train))\n",
    "print(len(X_test))\n",
    "print(len(y_train))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformulate the label. \n",
    "# If the digit is smaller than 5, the label is 0.\n",
    "# If the digit is larger than 5, the label is 1.\n",
    "\n",
    "y_train[y_train < 5 ] = 0\n",
    "y_train[y_train >= 5] = 1\n",
    "y_test[y_test < 5] = 0\n",
    "y_test[y_test >= 5] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1347, 64)\n",
      "(450, 64)\n",
      "(1347,)\n",
      "(450,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3- Architecture of the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./networks.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'pwd' 不是内部或外部命令，也不是可运行的程序\n",
      "或批处理文件。\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mathematical expression of the algorithm:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For one example $x^{(i)}$:   \n",
    " $$ z^{(i)} = w^T * x^{(i)} +b $$   \n",
    " $$ y^{(i)} = a^{(i)} = sigmoid(z^{(i)})$$   \n",
    " $$L(a^{(i)},y^{(i)}) = -y^{(i)} log(a^{(i)})-(1-y^{(i)})log(1-a^{(i)})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total cost over all training examples:\n",
    "$$ J = \\frac{1}{m}\\sum_{i=1}^{m}L(a^{(i)},y^{(i)}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 - Building the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1- Activation function    \n",
    "###### Exercise:\n",
    "Finish the sigmoid funciton "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.04742587317756679\n",
      "0.11920292202211757\n",
      "0.3775406687981454\n",
      "0.5\n",
      "0.6224593312018546\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def sigmoid(z):\n",
    "    '''\n",
    "    Compute the sigmoid of z\n",
    "    Arguments: z -- a scalar or numpy array of any size.\n",
    "    \n",
    "    Return:\n",
    "    s -- sigmoid(z)\n",
    "    '''\n",
    "    s = 1 / (1 + np.e**-z)\n",
    "    \n",
    "    return s\n",
    "\n",
    "print(sigmoid(-float('inf')))\n",
    "print(sigmoid(-3))\n",
    "print(sigmoid(-2))\n",
    "print(sigmoid(-0.5))\n",
    "print(sigmoid(0))\n",
    "print(sigmoid(0.5))\n",
    "print(sigmoid(float('inf')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid([0,2]) = [0.5        0.88079708]\n"
     ]
    }
   ],
   "source": [
    "# Test your code \n",
    "# The result should be [0.5 0.88079708]\n",
    "print(\"sigmoid([0,2]) = \" + str(sigmoid(np.array([0,2]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1-Initializaing parameters\n",
    "###### Exercise:\n",
    "Finishe the initialize_parameters function below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-2.01500966],\n",
       "        [ 0.53639962],\n",
       "        [-0.50617402],\n",
       "        [ 1.27720026],\n",
       "        [-1.18160265],\n",
       "        [ 0.12140143],\n",
       "        [-1.29950277],\n",
       "        [ 0.07358587],\n",
       "        [-0.36521343],\n",
       "        [ 1.29482372],\n",
       "        [-0.61142739],\n",
       "        [-0.73093048],\n",
       "        [ 0.70050572],\n",
       "        [-0.68236933],\n",
       "        [-0.17325968],\n",
       "        [ 0.6037009 ],\n",
       "        [ 0.44831095],\n",
       "        [ 0.68293564],\n",
       "        [-0.85312326],\n",
       "        [-2.2183101 ],\n",
       "        [ 0.05273869],\n",
       "        [-0.48121778],\n",
       "        [ 0.71296621],\n",
       "        [ 0.1430395 ],\n",
       "        [-0.84843656],\n",
       "        [-1.51854637],\n",
       "        [ 1.3104743 ],\n",
       "        [ 0.02216182],\n",
       "        [ 1.03475104],\n",
       "        [ 0.41421462],\n",
       "        [ 1.68217229],\n",
       "        [ 0.08816716],\n",
       "        [-0.67812601],\n",
       "        [-0.31018549],\n",
       "        [-0.95984678],\n",
       "        [ 0.34597767],\n",
       "        [-0.17743662],\n",
       "        [-0.46527971],\n",
       "        [ 0.03965588],\n",
       "        [-0.09686509],\n",
       "        [-0.543477  ],\n",
       "        [-0.90753426],\n",
       "        [ 1.62599986],\n",
       "        [-0.97241863],\n",
       "        [-0.72372282],\n",
       "        [ 1.52712669],\n",
       "        [ 1.08628883],\n",
       "        [-0.61217826],\n",
       "        [ 1.18408278],\n",
       "        [-1.53295829],\n",
       "        [ 1.49311846],\n",
       "        [ 0.3606363 ],\n",
       "        [ 1.71127562],\n",
       "        [ 1.16004764],\n",
       "        [ 0.75595585],\n",
       "        [ 0.68192386],\n",
       "        [-0.16439261],\n",
       "        [-0.20953079],\n",
       "        [ 0.06896244],\n",
       "        [-0.85923033],\n",
       "        [ 0.09594236],\n",
       "        [ 1.57314681],\n",
       "        [-0.76124117],\n",
       "        [-0.20704306]]), 5e-05)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random innitialize the parameters\n",
    "\n",
    "def initialize_parameters(dim):\n",
    "    '''\n",
    "    Argument: dim -- size of the w vector\n",
    "    \n",
    "    Returns:\n",
    "    w -- initialized vector of shape (dim,1)\n",
    "    b -- initializaed scalar\n",
    "    '''\n",
    "    \n",
    "    w = np.random.randn(dim, 1)\n",
    "    b = 0.00005\n",
    "    \n",
    "    assert(w.shape == (dim,1))\n",
    "    assert(isinstance(b,float) or isinstance(b,int))\n",
    "    \n",
    "    return w,b\n",
    "\n",
    "w,b = initialize_parameters(64)\n",
    "w,b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3-Forward and backward propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Some mathematical expressions\n",
    "Forward Propagation:   \n",
    ". X    \n",
    ". A = $\\sigma(w^T*X+b) = (a^{(1)},a^{(2)},...,a^{(m)}$   \n",
    ". J = $-\\frac{1}{m} \\sum_{i=1}^{m}y^{(i)}log(a^{(i)}+(1-y^{(i)})log(1-a^{(i)})$       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some derivative: \n",
    "$$\\frac{\\partial{J}}{\\partial{w}} = \\frac{1}{m}X*(A-Y)^T$$   \n",
    "$$\\frac{\\partial{J}}{\\partial{b}} = \\frac{1}{m}\\sum_{i=1}^m(a^{(i)}-y^{(i)}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Exercise:\n",
    "Finish the function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: RuntimeWarning: divide by zero encountered in log\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in multiply\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'dw': array([[ 0.00000000e+00],\n",
       "         [ 2.21991044e+00],\n",
       "         [ 3.20696308e+01],\n",
       "         [ 6.82703984e+01],\n",
       "         [ 6.17428181e+01],\n",
       "         [ 4.83166789e+00],\n",
       "         [-1.16758458e+01],\n",
       "         [-1.57124691e+00],\n",
       "         [ 2.91286405e-02],\n",
       "         [ 1.51219093e+01],\n",
       "         [ 5.42337678e+01],\n",
       "         [ 6.80920590e+01],\n",
       "         [ 7.71700746e+01],\n",
       "         [ 4.24595710e+01],\n",
       "         [-3.38169422e+00],\n",
       "         [-3.39532224e-01],\n",
       "         [ 3.12500000e-02],\n",
       "         [ 1.47272146e+01],\n",
       "         [ 4.61361124e+01],\n",
       "         [ 4.94428489e+01],\n",
       "         [ 6.57563844e+01],\n",
       "         [ 5.07232836e+01],\n",
       "         [ 1.21547278e+01],\n",
       "         [ 4.64820941e-01],\n",
       "         [ 1.92472223e-25],\n",
       "         [ 1.28133479e+01],\n",
       "         [ 4.09808610e+01],\n",
       "         [ 3.96261883e+01],\n",
       "         [ 5.61046238e+01],\n",
       "         [ 4.34679674e+01],\n",
       "         [ 1.89545642e+01],\n",
       "         [ 3.12500000e-02],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 1.84846025e+01],\n",
       "         [ 3.24113272e+01],\n",
       "         [ 2.46111577e+01],\n",
       "         [ 4.82451532e+01],\n",
       "         [ 5.31511162e+01],\n",
       "         [ 1.84595807e+01],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 1.25010892e-01],\n",
       "         [ 1.63482683e+01],\n",
       "         [ 5.11839721e+01],\n",
       "         [ 2.94248212e+01],\n",
       "         [ 3.34963555e+01],\n",
       "         [ 7.02273246e+01],\n",
       "         [ 2.95693237e+01],\n",
       "         [ 3.12499999e-02],\n",
       "         [ 1.25357994e-01],\n",
       "         [ 6.95801230e+00],\n",
       "         [ 6.61659180e+01],\n",
       "         [ 5.27140402e+01],\n",
       "         [ 7.72159376e+01],\n",
       "         [ 9.85508911e+01],\n",
       "         [ 3.71489387e+01],\n",
       "         [ 3.05023819e+00],\n",
       "         [ 1.18424412e-04],\n",
       "         [ 1.61325703e+00],\n",
       "         [ 3.14458913e+01],\n",
       "         [ 6.89457226e+01],\n",
       "         [ 1.08143732e+02],\n",
       "         [ 7.42020225e+01],\n",
       "         [ 2.64262600e+01],\n",
       "         [ 7.10161022e+00]]), 'db': 6.123917441187416}, nan)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def propagate(w,b,X,Y):\n",
    "    '''\n",
    "    Implement the cost function and its gradient for the propagation\n",
    "    \n",
    "    Arguments:\n",
    "    w - weights\n",
    "    b - bias\n",
    "    X - data\n",
    "    Y - ground truth\n",
    "    '''\n",
    "    m = X.shape[1]\n",
    "#     print(m, \"w.shape\", w.shape, 'X.shape', X.shape)\n",
    "    A = sigmoid(np.dot(X, w) + b).reshape(-1)\n",
    "#     print(\"A.shape\", A.shape, \"Y.shape\", Y.shape, (A - Y).shape)\n",
    "    cost = -1/m * np.sum([y * np.log(a) + (1 - y)* np.log(1 - a) for y, a in zip(Y, A)])\n",
    "    \n",
    "    dw = 1/m * np.dot(X.T , (A - Y)).reshape(-1,1)\n",
    "#     print(\"dw.shape\", dw.shape)\n",
    "    db = 1/m * np.sum([a - y for y, a in zip(Y, A)])\n",
    "#     print(\"db\", db)\n",
    "    \n",
    "    assert(dw.shape == w.shape)\n",
    "    assert(db.dtype == float)\n",
    "    cost = np.squeeze(cost)\n",
    "    assert(cost.shape == ())\n",
    "    \n",
    "    grads = {'dw':dw,\n",
    "             'db':db}\n",
    "    return grads, cost\n",
    "\n",
    "# grads, cost = propagate(w,b,X_train[:30],y_train[:30])\n",
    "grads, cost = propagate(w,b,X_train,y_train)\n",
    "grads, cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.4 -Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Exercise:\n",
    "Minimizing the cost function using gradient descent.   \n",
    "$$\\theta = \\theta - \\alpha*d\\theta$$ where $\\alpha$ is the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: RuntimeWarning: divide by zero encountered in log\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in multiply\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: nan\n",
      "Cost after iteration 100: nan\n",
      "Cost after iteration 200: nan\n",
      "Cost after iteration 300: nan\n",
      "Cost after iteration 400: nan\n",
      "Cost after iteration 500: nan\n",
      "Cost after iteration 600: nan\n",
      "Cost after iteration 700: 9.606195\n",
      "Cost after iteration 800: 8.661677\n",
      "Cost after iteration 900: 7.905963\n",
      "Cost after iteration 1000: 7.402149\n",
      "Cost after iteration 1100: 9.115968\n",
      "Cost after iteration 1200: 10.254528\n",
      "Cost after iteration 1300: 8.911429\n",
      "Cost after iteration 1400: 7.637394\n",
      "Cost after iteration 1500: 6.616276\n",
      "Cost after iteration 1600: 6.442655\n",
      "Cost after iteration 1700: 6.319635\n",
      "Cost after iteration 1800: 6.228379\n",
      "Cost after iteration 1900: 6.170557\n"
     ]
    }
   ],
   "source": [
    "def optimize(w, b, X, Y, num_iterations, learning_rate, print_cost=False):\n",
    "    '''\n",
    "    This function optimize w and b by running a gradient descen algorithm\n",
    "    \n",
    "    Arguments:\n",
    "    w - weights\n",
    "    b - bias\n",
    "    X - data\n",
    "    Y - ground truth\n",
    "    num_iterations -- number of iterations of the optimization loop\n",
    "    learning_rate -- learning rate of the gradient descent update rule\n",
    "    print_cost -- True to print the loss every 100 steps\n",
    "    \n",
    "    Returns:\n",
    "    params - dictionary containing the weights w and bias b\n",
    "    grads -- dictionary containing the gradients of the weights and bias with respect to the cost function\n",
    "    costs -- list of all the costs computed during the optimization, this will be used to plot the learning curve.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    costs = []\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        \n",
    "        grads, cost = propagate(w,b,X,Y)\n",
    "        \n",
    "        dw = grads['dw']\n",
    "        db = grads['db']\n",
    "        \n",
    "        w = w - learning_rate * dw\n",
    "        b = b - learning_rate * db\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "    \n",
    "    params = {\"w\":w,\n",
    "              \"b\":b}\n",
    "    \n",
    "    grads = {\"dw\":dw,\n",
    "             \"db\":db}\n",
    "    \n",
    "    return params, grads, costs\n",
    "\n",
    "params, grads, costs = optimize(w,b,X_train,y_train, 2000, 0.001, print_cost=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Exercise\n",
    "The previous function will output the learned w and b. We are able to use w and b to predict the labels for a dataset X. Implement the predict() function.    \n",
    "Two steps to finish this task:   \n",
    "1. Calculate $\\hat{Y} = A = \\sigma(w^T*X+b)$   \n",
    "2. Convert the entries of a into 0 (if activation <= 0.5) or 1 (if activation > 0.5), stores the predictions in a vector Y_prediction. If you wish, you can use an if/else statement in a for loop (though there is also a way to vectorize this)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True, False, False,  True, False,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True, False,  True,  True,  True,  True, False,  True,\n",
       "         True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        False,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "         True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True, False,  True,  True,  True,  True, False,\n",
       "         True,  True,  True,  True,  True, False, False,  True,  True,\n",
       "         True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "         True,  True, False,  True, False,  True,  True,  True,  True,\n",
       "         True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True, False,  True,  True, False,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        False,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "        False,  True,  True,  True, False,  True, False,  True, False,\n",
       "         True,  True,  True,  True, False,  True,  True,  True, False,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True, False, False,  True,  True,\n",
       "         True, False,  True,  True,  True,  True, False,  True,  True,\n",
       "         True,  True, False,  True,  True,  True, False,  True,  True,\n",
       "         True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True, False, False,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "         True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True, False, False,  True,  True,  True,  True,  True,\n",
       "        False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True, False, False,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "         True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "        False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        False, False, False,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "        False,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "        False, False,  True,  True,  True,  True, False,  True,  True,\n",
       "        False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True, False]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(w, b, X):\n",
    "    '''\n",
    "    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n",
    "    \n",
    "    Arguments:\n",
    "    w -- weights\n",
    "    b -- bias \n",
    "    X -- data \n",
    "    \n",
    "    Returns:\n",
    "    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n",
    "    '''\n",
    "    m = X.shape[0]\n",
    "    Y_prediction = np.zeros((1,m))\n",
    "    w = w.reshape(X.shape[1],1)\n",
    "    \n",
    "    A = sigmoid(np.dot(X, w) + b).reshape(-1)\n",
    "    \n",
    "    for i in range(A.shape[0]):\n",
    "        Y_prediction[0][i] = 1 if A[i] > 0.5 else 0\n",
    "    \n",
    "    assert(Y_prediction.shape == (1,m))\n",
    "    \n",
    "    return Y_prediction\n",
    "\n",
    "Y_prediction = predict(params['w'], params['b'], X_test)\n",
    "Y_prediction == y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5- Merge all functions into a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations !! You have finished all the necessary components for constructing a model. Now, Let's take the challenge to merge all the implemented function into one model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: RuntimeWarning: divide by zero encountered in log\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in multiply\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({True: 1200, False: 147})\n",
      "Counter({True: 386, False: 64})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'w': array([[ 1.33673857],\n",
       "        [ 1.59298726],\n",
       "        [ 0.51346661],\n",
       "        [-0.86312536],\n",
       "        [ 1.10432019],\n",
       "        [ 0.06086872],\n",
       "        [ 1.66827423],\n",
       "        [-0.25193959],\n",
       "        [-0.06721052],\n",
       "        [-0.20878884],\n",
       "        [-0.04283784],\n",
       "        [-2.32510607],\n",
       "        [ 2.11276406],\n",
       "        [ 0.15470166],\n",
       "        [ 0.06681873],\n",
       "        [-0.43681655],\n",
       "        [-1.23360354],\n",
       "        [ 0.68563972],\n",
       "        [-1.99576039],\n",
       "        [ 0.61538663],\n",
       "        [-0.76724765],\n",
       "        [ 0.92882848],\n",
       "        [-1.02509691],\n",
       "        [ 1.11374444],\n",
       "        [-1.27474492],\n",
       "        [-0.01536492],\n",
       "        [-1.19688636],\n",
       "        [-1.35050504],\n",
       "        [-1.03302505],\n",
       "        [ 0.78759415],\n",
       "        [-1.57501111],\n",
       "        [-0.38908091],\n",
       "        [-1.23871213],\n",
       "        [ 1.22640845],\n",
       "        [-0.63536842],\n",
       "        [-2.33562571],\n",
       "        [ 0.41119595],\n",
       "        [ 0.69556725],\n",
       "        [-0.40571587],\n",
       "        [-0.54364368],\n",
       "        [ 0.31175355],\n",
       "        [-0.56089784],\n",
       "        [-0.50741038],\n",
       "        [-0.88165278],\n",
       "        [-0.75187544],\n",
       "        [ 0.44967671],\n",
       "        [-1.75952365],\n",
       "        [-0.8623421 ],\n",
       "        [-0.78929836],\n",
       "        [ 0.96666584],\n",
       "        [-0.80239899],\n",
       "        [ 1.17038047],\n",
       "        [ 0.24713465],\n",
       "        [-1.1191282 ],\n",
       "        [-0.65515417],\n",
       "        [-0.60758379],\n",
       "        [-0.48079639],\n",
       "        [-0.03730098],\n",
       "        [ 0.32416402],\n",
       "        [ 0.56643385],\n",
       "        [ 0.21513016],\n",
       "        [ 0.06130767],\n",
       "        [-1.9757644 ],\n",
       "        [-0.17623843]]),\n",
       " 'b': 5e-05,\n",
       " 'training_accuracy': 0.89086859688196,\n",
       " 'test_accuracy': 0.8577777777777778,\n",
       " 'cost': [inf,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  8.299612736666376,\n",
       "  7.715195756739087,\n",
       "  7.600627912206909,\n",
       "  8.220008418857088,\n",
       "  nan,\n",
       "  8.617194740099176,\n",
       "  8.897842564329611,\n",
       "  nan,\n",
       "  nan,\n",
       "  7.2682040309569915,\n",
       "  6.392837884954469,\n",
       "  6.3629286444766695,\n",
       "  6.369203289687459,\n",
       "  6.392670268780425,\n",
       "  6.433367802983145,\n",
       "  6.493259573413022,\n",
       "  6.576989018614828,\n",
       "  6.698471400635679,\n",
       "  7.154264012849465,\n",
       "  nan,\n",
       "  nan,\n",
       "  10.26703673848335,\n",
       "  6.229247703700867,\n",
       "  6.0716334546867685,\n",
       "  6.080351047512535,\n",
       "  6.104660391182458,\n",
       "  6.133600158127319,\n",
       "  6.166183407454216,\n",
       "  6.202554490980928,\n",
       "  6.243189713213319,\n",
       "  6.288740268536781,\n",
       "  6.339953074184537,\n",
       "  6.398126772824193,\n",
       "  6.46532648974163,\n",
       "  6.547475639001165,\n",
       "  6.679407573043053,\n",
       "  7.167262291937426,\n",
       "  10.099900895504721,\n",
       "  21.807645413182577,\n",
       "  nan,\n",
       "  47.83861303796893,\n",
       "  13.078665578097306]}"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, num_iterations, learning_rate, print_cost):\n",
    "    \"\"\"\n",
    "    Build the logistic regression model by calling all the functions you have implemented.\n",
    "    Arguments:\n",
    "    X_train - training set\n",
    "    Y_train - training label\n",
    "    X_test - test set\n",
    "    Y_test - test label\n",
    "    num_iteration - hyperparameter representing the number of iterations to optimize the parameters\n",
    "    learning_rate -- hyperparameter representing the learning rate used in the update rule of optimize()\n",
    "    print_cost -- Set to true to print the cost every 100 iterations\n",
    "    \n",
    "    Returns:\n",
    "    d - dictionary should contain following information w,b,training_accuracy, test_accuracy,cost\n",
    "    eg: d = {\"w\":w,\n",
    "             \"b\":b,\n",
    "             \"training_accuracy\": traing_accuracy,\n",
    "             \"test_accuracy\":test_accuracy,\n",
    "             \"cost\":cost}\n",
    "    \"\"\"\n",
    "    w,b = initialize_parameters(X_train.shape[1])\n",
    "    params, grads, costs = optimize(w, b, X_train, Y_train, num_iterations, learning_rate, print_cost=print_cost)\n",
    "    \n",
    "    Y_prediction = predict(params['w'], params['b'], X_train)\n",
    "    counter = Counter(list((Y_prediction == Y_train).reshape(-1)))\n",
    "    print(counter)\n",
    "    traing_accuracy = counter[True]/len(Y_train)\n",
    "    \n",
    "    Y_prediction = predict(params['w'], params['b'], X_test)\n",
    "    counter = Counter(list((Y_prediction == Y_test).reshape(-1)))\n",
    "    print(counter)\n",
    "    test_accuracy = counter[True]/len(Y_test)\n",
    "    \n",
    "    return {\"w\":w,\n",
    "             \"b\":b,\n",
    "             \"training_accuracy\": traing_accuracy,\n",
    "             \"test_accuracy\":test_accuracy,\n",
    "             \"cost\":costs}\n",
    "\n",
    "result = model(X_train, y_train, X_test, y_test, 5000, 0.001, print_cost=False)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1587d81b988>"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(range(len(result['cost'])), result['cost'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用keras 看下能做到那一步"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1347/1347 [==============================] - 1s 791us/step - loss: 1.0369 - mean_squared_error: 0.2334\n",
      "Epoch 2/500\n",
      "1347/1347 [==============================] - 0s 99us/step - loss: 0.3115 - mean_squared_error: 0.0944\n",
      "Epoch 3/500\n",
      "1347/1347 [==============================] - 0s 67us/step - loss: 0.2251 - mean_squared_error: 0.0636\n",
      "Epoch 4/500\n",
      "1347/1347 [==============================] - 0s 57us/step - loss: 0.1838 - mean_squared_error: 0.0502\n",
      "Epoch 5/500\n",
      "1347/1347 [==============================] - 0s 57us/step - loss: 0.1673 - mean_squared_error: 0.0458\n",
      "Epoch 6/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 0.1597 - mean_squared_error: 0.0443\n",
      "Epoch 7/500\n",
      "1347/1347 [==============================] - 0s 57us/step - loss: 0.1352 - mean_squared_error: 0.0366\n",
      "Epoch 8/500\n",
      "1347/1347 [==============================] - 0s 59us/step - loss: 0.1269 - mean_squared_error: 0.0329\n",
      "Epoch 9/500\n",
      "1347/1347 [==============================] - 0s 64us/step - loss: 0.1152 - mean_squared_error: 0.0292\n",
      "Epoch 10/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 0.1043 - mean_squared_error: 0.0271\n",
      "Epoch 11/500\n",
      "1347/1347 [==============================] - 0s 54us/step - loss: 0.0970 - mean_squared_error: 0.0246\n",
      "Epoch 12/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 0.0913 - mean_squared_error: 0.0231\n",
      "Epoch 13/500\n",
      "1347/1347 [==============================] - 0s 53us/step - loss: 0.0866 - mean_squared_error: 0.0221\n",
      "Epoch 14/500\n",
      "1347/1347 [==============================] - 0s 59us/step - loss: 0.0795 - mean_squared_error: 0.0194\n",
      "Epoch 15/500\n",
      "1347/1347 [==============================] - 0s 57us/step - loss: 0.0747 - mean_squared_error: 0.0182\n",
      "Epoch 16/500\n",
      "1347/1347 [==============================] - 0s 55us/step - loss: 0.0724 - mean_squared_error: 0.0172\n",
      "Epoch 17/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 0.0705 - mean_squared_error: 0.0171\n",
      "Epoch 18/500\n",
      "1347/1347 [==============================] - 0s 53us/step - loss: 0.0645 - mean_squared_error: 0.0159\n",
      "Epoch 19/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 0.0632 - mean_squared_error: 0.0154\n",
      "Epoch 20/500\n",
      "1347/1347 [==============================] - 0s 53us/step - loss: 0.0570 - mean_squared_error: 0.0132\n",
      "Epoch 21/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 0.0555 - mean_squared_error: 0.0131\n",
      "Epoch 22/500\n",
      "1347/1347 [==============================] - 0s 54us/step - loss: 0.0532 - mean_squared_error: 0.0123\n",
      "Epoch 23/500\n",
      "1347/1347 [==============================] - 0s 61us/step - loss: 0.0546 - mean_squared_error: 0.0131\n",
      "Epoch 24/500\n",
      "1347/1347 [==============================] - 0s 64us/step - loss: 0.0839 - mean_squared_error: 0.0206\n",
      "Epoch 25/500\n",
      "1347/1347 [==============================] - 0s 54us/step - loss: 0.0485 - mean_squared_error: 0.0111\n",
      "Epoch 26/500\n",
      "1347/1347 [==============================] - 0s 57us/step - loss: 0.0457 - mean_squared_error: 0.0101\n",
      "Epoch 27/500\n",
      "1347/1347 [==============================] - 0s 57us/step - loss: 0.0431 - mean_squared_error: 0.0096\n",
      "Epoch 28/500\n",
      "1347/1347 [==============================] - 0s 54us/step - loss: 0.0417 - mean_squared_error: 0.0096\n",
      "Epoch 29/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 0.0384 - mean_squared_error: 0.0082\n",
      "Epoch 30/500\n",
      "1347/1347 [==============================] - 0s 55us/step - loss: 0.0390 - mean_squared_error: 0.0083\n",
      "Epoch 31/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 0.0358 - mean_squared_error: 0.0077\n",
      "Epoch 32/500\n",
      "1347/1347 [==============================] - 0s 53us/step - loss: 0.0340 - mean_squared_error: 0.0070\n",
      "Epoch 33/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 0.0323 - mean_squared_error: 0.0068\n",
      "Epoch 34/500\n",
      "1347/1347 [==============================] - 0s 54us/step - loss: 0.0312 - mean_squared_error: 0.0064\n",
      "Epoch 35/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 0.0300 - mean_squared_error: 0.0060\n",
      "Epoch 36/500\n",
      "1347/1347 [==============================] - 0s 57us/step - loss: 0.0305 - mean_squared_error: 0.0066\n",
      "Epoch 37/500\n",
      "1347/1347 [==============================] - 0s 53us/step - loss: 0.0535 - mean_squared_error: 0.0129\n",
      "Epoch 38/500\n",
      "1347/1347 [==============================] - 0s 61us/step - loss: 0.0286 - mean_squared_error: 0.0059\n",
      "Epoch 39/500\n",
      "1347/1347 [==============================] - 0s 61us/step - loss: 0.0249 - mean_squared_error: 0.0047\n",
      "Epoch 40/500\n",
      "1347/1347 [==============================] - 0s 61us/step - loss: 0.0254 - mean_squared_error: 0.0051\n",
      "Epoch 41/500\n",
      "1347/1347 [==============================] - 0s 55us/step - loss: 0.0238 - mean_squared_error: 0.0045\n",
      "Epoch 42/500\n",
      "1347/1347 [==============================] - 0s 58us/step - loss: 0.0231 - mean_squared_error: 0.0043\n",
      "Epoch 43/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 0.0274 - mean_squared_error: 0.0061\n",
      "Epoch 44/500\n",
      "1347/1347 [==============================] - 0s 53us/step - loss: 0.0284 - mean_squared_error: 0.0060\n",
      "Epoch 45/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 0.0207 - mean_squared_error: 0.0034\n",
      "Epoch 46/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 0.0201 - mean_squared_error: 0.0035\n",
      "Epoch 47/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 0.0195 - mean_squared_error: 0.0034\n",
      "Epoch 48/500\n",
      "1347/1347 [==============================] - 0s 54us/step - loss: 0.0182 - mean_squared_error: 0.0030\n",
      "Epoch 49/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 0.0177 - mean_squared_error: 0.0029\n",
      "Epoch 50/500\n",
      "1347/1347 [==============================] - 0s 59us/step - loss: 0.0191 - mean_squared_error: 0.0035\n",
      "Epoch 51/500\n",
      "1347/1347 [==============================] - 0s 54us/step - loss: 0.0173 - mean_squared_error: 0.0029\n",
      "Epoch 52/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 0.0156 - mean_squared_error: 0.0021\n",
      "Epoch 53/500\n",
      "1347/1347 [==============================] - 0s 64us/step - loss: 0.0153 - mean_squared_error: 0.0023\n",
      "Epoch 54/500\n",
      "1347/1347 [==============================] - 0s 67us/step - loss: 0.0147 - mean_squared_error: 0.0020\n",
      "Epoch 55/500\n",
      "1347/1347 [==============================] - 0s 57us/step - loss: 0.0142 - mean_squared_error: 0.0019\n",
      "Epoch 56/500\n",
      "1347/1347 [==============================] - 0s 55us/step - loss: 0.0148 - mean_squared_error: 0.0021\n",
      "Epoch 57/500\n",
      "1347/1347 [==============================] - 0s 57us/step - loss: 0.0145 - mean_squared_error: 0.0022\n",
      "Epoch 58/500\n",
      "1347/1347 [==============================] - 0s 53us/step - loss: 0.0145 - mean_squared_error: 0.0021\n",
      "Epoch 59/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 0.0130 - mean_squared_error: 0.0017\n",
      "Epoch 60/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 0.0124 - mean_squared_error: 0.0015\n",
      "Epoch 61/500\n",
      "1347/1347 [==============================] - 0s 55us/step - loss: 0.0121 - mean_squared_error: 0.0015\n",
      "Epoch 62/500\n",
      "1347/1347 [==============================] - 0s 58us/step - loss: 0.0116 - mean_squared_error: 0.0013\n",
      "Epoch 63/500\n",
      "1347/1347 [==============================] - 0s 60us/step - loss: 0.0115 - mean_squared_error: 0.0013\n",
      "Epoch 64/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 0.0110 - mean_squared_error: 0.0012\n",
      "Epoch 65/500\n",
      "1347/1347 [==============================] - 0s 58us/step - loss: 0.0110 - mean_squared_error: 0.0012\n",
      "Epoch 66/500\n",
      "1347/1347 [==============================] - 0s 57us/step - loss: 0.0107 - mean_squared_error: 0.0012\n",
      "Epoch 67/500\n",
      "1347/1347 [==============================] - 0s 58us/step - loss: 0.0104 - mean_squared_error: 0.0012\n",
      "Epoch 68/500\n",
      "1347/1347 [==============================] - 0s 59us/step - loss: 0.0100 - mean_squared_error: 0.0011\n",
      "Epoch 69/500\n",
      "1347/1347 [==============================] - 0s 61us/step - loss: 0.0099 - mean_squared_error: 0.0010\n",
      "Epoch 70/500\n",
      "1347/1347 [==============================] - 0s 58us/step - loss: 0.0097 - mean_squared_error: 9.5651e-04\n",
      "Epoch 71/500\n",
      "1347/1347 [==============================] - 0s 53us/step - loss: 0.0094 - mean_squared_error: 9.0776e-04\n",
      "Epoch 72/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1347/1347 [==============================] - 0s 56us/step - loss: 0.0094 - mean_squared_error: 0.0010\n",
      "Epoch 73/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 0.0088 - mean_squared_error: 7.6984e-04\n",
      "Epoch 74/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 0.0089 - mean_squared_error: 8.7154e-04\n",
      "Epoch 75/500\n",
      "1347/1347 [==============================] - 0s 57us/step - loss: 0.0088 - mean_squared_error: 8.4335e-04\n",
      "Epoch 76/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 0.0100 - mean_squared_error: 0.0012\n",
      "Epoch 77/500\n",
      "1347/1347 [==============================] - 0s 64us/step - loss: 0.0086 - mean_squared_error: 7.8735e-04\n",
      "Epoch 78/500\n",
      "1347/1347 [==============================] - 0s 59us/step - loss: 0.0083 - mean_squared_error: 7.5825e-04\n",
      "Epoch 79/500\n",
      "1347/1347 [==============================] - 0s 55us/step - loss: 0.0080 - mean_squared_error: 6.7447e-04\n",
      "Epoch 80/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 0.0080 - mean_squared_error: 7.1056e-04\n",
      "Epoch 81/500\n",
      "1347/1347 [==============================] - 0s 55us/step - loss: 0.0078 - mean_squared_error: 6.3747e-04\n",
      "Epoch 82/500\n",
      "1347/1347 [==============================] - 0s 59us/step - loss: 0.0076 - mean_squared_error: 6.2157e-04\n",
      "Epoch 83/500\n",
      "1347/1347 [==============================] - 0s 60us/step - loss: 0.0076 - mean_squared_error: 6.5026e-04\n",
      "Epoch 84/500\n",
      "1347/1347 [==============================] - 0s 59us/step - loss: 0.0071 - mean_squared_error: 5.2066e-04\n",
      "Epoch 85/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 0.0071 - mean_squared_error: 5.4298e-04\n",
      "Epoch 86/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 0.0071 - mean_squared_error: 5.6982e-04\n",
      "Epoch 87/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 0.0069 - mean_squared_error: 5.3859e-04\n",
      "Epoch 88/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 0.0066 - mean_squared_error: 4.5715e-04\n",
      "Epoch 89/500\n",
      "1347/1347 [==============================] - 0s 55us/step - loss: 0.0069 - mean_squared_error: 5.2091e-04\n",
      "Epoch 90/500\n",
      "1347/1347 [==============================] - 0s 54us/step - loss: 0.0067 - mean_squared_error: 4.8757e-04\n",
      "Epoch 91/500\n",
      "1347/1347 [==============================] - 0s 58us/step - loss: 0.0064 - mean_squared_error: 4.5136e-04\n",
      "Epoch 92/500\n",
      "1347/1347 [==============================] - 0s 54us/step - loss: 0.0062 - mean_squared_error: 4.1062e-04\n",
      "Epoch 93/500\n",
      "1347/1347 [==============================] - 0s 57us/step - loss: 0.0063 - mean_squared_error: 4.4611e-04\n",
      "Epoch 94/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 0.0060 - mean_squared_error: 3.8563e-04\n",
      "Epoch 95/500\n",
      "1347/1347 [==============================] - 0s 55us/step - loss: 0.0059 - mean_squared_error: 3.7410e-04\n",
      "Epoch 96/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 0.0058 - mean_squared_error: 3.5163e-04\n",
      "Epoch 97/500\n",
      "1347/1347 [==============================] - 0s 58us/step - loss: 0.0060 - mean_squared_error: 4.2777e-04\n",
      "Epoch 98/500\n",
      "1347/1347 [==============================] - 0s 61us/step - loss: 0.0058 - mean_squared_error: 4.0438e-04\n",
      "Epoch 99/500\n",
      "1347/1347 [==============================] - 0s 60us/step - loss: 0.0056 - mean_squared_error: 3.6481e-04\n",
      "Epoch 100/500\n",
      "1347/1347 [==============================] - 0s 55us/step - loss: 0.0055 - mean_squared_error: 3.2977e-04\n",
      "Epoch 101/500\n",
      "1347/1347 [==============================] - 0s 57us/step - loss: 0.0054 - mean_squared_error: 3.1862e-04\n",
      "Epoch 102/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 0.0053 - mean_squared_error: 3.0361e-04\n",
      "Epoch 103/500\n",
      "1347/1347 [==============================] - 0s 55us/step - loss: 0.0053 - mean_squared_error: 3.2223e-04\n",
      "Epoch 104/500\n",
      "1347/1347 [==============================] - 0s 59us/step - loss: 0.0052 - mean_squared_error: 3.0263e-04\n",
      "Epoch 105/500\n",
      "1347/1347 [==============================] - 0s 54us/step - loss: 0.0051 - mean_squared_error: 2.9527e-04\n",
      "Epoch 106/500\n",
      "1347/1347 [==============================] - 0s 57us/step - loss: 0.0051 - mean_squared_error: 3.1633e-04\n",
      "Epoch 107/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 0.0050 - mean_squared_error: 2.8380e-04\n",
      "Epoch 108/500\n",
      "1347/1347 [==============================] - 0s 57us/step - loss: 0.0050 - mean_squared_error: 2.9059e-04\n",
      "Epoch 109/500\n",
      "1347/1347 [==============================] - 0s 55us/step - loss: 0.0048 - mean_squared_error: 2.6419e-04\n",
      "Epoch 110/500\n",
      "1347/1347 [==============================] - 0s 55us/step - loss: 0.0048 - mean_squared_error: 2.4013e-04\n",
      "Epoch 111/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 0.0048 - mean_squared_error: 2.6577e-04\n",
      "Epoch 112/500\n",
      "1347/1347 [==============================] - 0s 61us/step - loss: 0.0047 - mean_squared_error: 2.3918e-04\n",
      "Epoch 113/500\n",
      "1347/1347 [==============================] - 0s 60us/step - loss: 0.0054 - mean_squared_error: 3.7686e-04\n",
      "Epoch 114/500\n",
      "1347/1347 [==============================] - 0s 61us/step - loss: 0.0045 - mean_squared_error: 2.1881e-04\n",
      "Epoch 115/500\n",
      "1347/1347 [==============================] - 0s 55us/step - loss: 0.0044 - mean_squared_error: 2.1760e-04\n",
      "Epoch 116/500\n",
      "1347/1347 [==============================] - 0s 61us/step - loss: 0.0043 - mean_squared_error: 2.0740e-04\n",
      "Epoch 117/500\n",
      "1347/1347 [==============================] - 0s 61us/step - loss: 0.0044 - mean_squared_error: 2.0418e-04\n",
      "Epoch 118/500\n",
      "1347/1347 [==============================] - 0s 53us/step - loss: 0.0043 - mean_squared_error: 1.9879e-04\n",
      "Epoch 119/500\n",
      "1347/1347 [==============================] - 0s 58us/step - loss: 0.0042 - mean_squared_error: 1.9438e-04\n",
      "Epoch 120/500\n",
      "1347/1347 [==============================] - 0s 54us/step - loss: 0.0043 - mean_squared_error: 2.1121e-04\n",
      "Epoch 121/500\n",
      "1347/1347 [==============================] - 0s 57us/step - loss: 0.0042 - mean_squared_error: 1.9821e-04\n",
      "Epoch 122/500\n",
      "1347/1347 [==============================] - 0s 57us/step - loss: 0.0040 - mean_squared_error: 1.7691e-04\n",
      "Epoch 123/500\n",
      "1347/1347 [==============================] - 0s 54us/step - loss: 0.0040 - mean_squared_error: 1.8942e-04\n",
      "Epoch 124/500\n",
      "1347/1347 [==============================] - 0s 58us/step - loss: 0.0040 - mean_squared_error: 1.9303e-04\n",
      "Epoch 125/500\n",
      "1347/1347 [==============================] - 0s 53us/step - loss: 0.0038 - mean_squared_error: 1.5360e-04\n",
      "Epoch 126/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 0.0040 - mean_squared_error: 1.7983e-04\n",
      "Epoch 127/500\n",
      "1347/1347 [==============================] - 0s 63us/step - loss: 0.0038 - mean_squared_error: 1.6824e-04\n",
      "Epoch 128/500\n",
      "1347/1347 [==============================] - 0s 63us/step - loss: 0.0038 - mean_squared_error: 1.6335e-04\n",
      "Epoch 129/500\n",
      "1347/1347 [==============================] - 0s 61us/step - loss: 0.0037 - mean_squared_error: 1.5560e-04\n",
      "Epoch 130/500\n",
      "1347/1347 [==============================] - 0s 59us/step - loss: 0.0037 - mean_squared_error: 1.5545e-04\n",
      "Epoch 131/500\n",
      "1347/1347 [==============================] - 0s 58us/step - loss: 0.0037 - mean_squared_error: 1.4908e-04\n",
      "Epoch 132/500\n",
      "1347/1347 [==============================] - 0s 61us/step - loss: 0.0036 - mean_squared_error: 1.3955e-04\n",
      "Epoch 133/500\n",
      "1347/1347 [==============================] - 0s 54us/step - loss: 0.0036 - mean_squared_error: 1.3927e-04\n",
      "Epoch 134/500\n",
      "1347/1347 [==============================] - 0s 67us/step - loss: 0.0042 - mean_squared_error: 2.7985e-04\n",
      "Epoch 135/500\n",
      "1347/1347 [==============================] - 0s 53us/step - loss: 0.0036 - mean_squared_error: 1.5297e-04\n",
      "Epoch 136/500\n",
      "1347/1347 [==============================] - 0s 57us/step - loss: 0.0036 - mean_squared_error: 1.5828e-04\n",
      "Epoch 137/500\n",
      "1347/1347 [==============================] - 0s 58us/step - loss: 0.0037 - mean_squared_error: 1.6954e-04\n",
      "Epoch 138/500\n",
      "1347/1347 [==============================] - 0s 58us/step - loss: 0.0034 - mean_squared_error: 1.3164e-04\n",
      "Epoch 139/500\n",
      "1347/1347 [==============================] - 0s 93us/step - loss: 0.0033 - mean_squared_error: 1.2814e-04\n",
      "Epoch 140/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1347/1347 [==============================] - 0s 65us/step - loss: 0.0033 - mean_squared_error: 1.1997e-04\n",
      "Epoch 141/500\n",
      "1347/1347 [==============================] - 0s 75us/step - loss: 0.0033 - mean_squared_error: 1.1651e-04\n",
      "Epoch 142/500\n",
      "1347/1347 [==============================] - 0s 74us/step - loss: 0.0032 - mean_squared_error: 1.0410e-04\n",
      "Epoch 143/500\n",
      "1347/1347 [==============================] - 0s 67us/step - loss: 0.0032 - mean_squared_error: 1.1842e-04\n",
      "Epoch 144/500\n",
      "1347/1347 [==============================] - 0s 66us/step - loss: 0.0032 - mean_squared_error: 1.1231e-04\n",
      "Epoch 145/500\n",
      "1347/1347 [==============================] - 0s 66us/step - loss: 0.0031 - mean_squared_error: 1.0787e-04\n",
      "Epoch 146/500\n",
      "1347/1347 [==============================] - 0s 64us/step - loss: 0.0031 - mean_squared_error: 1.0689e-04\n",
      "Epoch 147/500\n",
      "1347/1347 [==============================] - 0s 64us/step - loss: 0.0031 - mean_squared_error: 1.0590e-04\n",
      "Epoch 148/500\n",
      "1347/1347 [==============================] - 0s 63us/step - loss: 0.0032 - mean_squared_error: 1.1547e-04\n",
      "Epoch 149/500\n",
      "1347/1347 [==============================] - 0s 64us/step - loss: 0.0030 - mean_squared_error: 9.5867e-05\n",
      "Epoch 150/500\n",
      "1347/1347 [==============================] - 0s 68us/step - loss: 0.0030 - mean_squared_error: 9.9288e-05\n",
      "Epoch 151/500\n",
      "1347/1347 [==============================] - 0s 62us/step - loss: 0.0029 - mean_squared_error: 9.5524e-05\n",
      "Epoch 152/500\n",
      "1347/1347 [==============================] - 0s 67us/step - loss: 0.0029 - mean_squared_error: 9.5072e-05\n",
      "Epoch 153/500\n",
      "1347/1347 [==============================] - 0s 65us/step - loss: 0.0029 - mean_squared_error: 9.3251e-05\n",
      "Epoch 154/500\n",
      "1347/1347 [==============================] - 0s 67us/step - loss: 0.0029 - mean_squared_error: 9.1810e-05\n",
      "Epoch 155/500\n",
      "1347/1347 [==============================] - 0s 69us/step - loss: 0.0029 - mean_squared_error: 9.1327e-05\n",
      "Epoch 156/500\n",
      "1347/1347 [==============================] - 0s 61us/step - loss: 0.0028 - mean_squared_error: 8.5039e-05\n",
      "Epoch 157/500\n",
      "1347/1347 [==============================] - 0s 62us/step - loss: 0.0028 - mean_squared_error: 8.6122e-05\n",
      "Epoch 158/500\n",
      "1347/1347 [==============================] - 0s 64us/step - loss: 0.0027 - mean_squared_error: 8.1321e-05\n",
      "Epoch 159/500\n",
      "1347/1347 [==============================] - 0s 65us/step - loss: 0.0028 - mean_squared_error: 9.0000e-05\n",
      "Epoch 160/500\n",
      "1347/1347 [==============================] - 0s 65us/step - loss: 0.0027 - mean_squared_error: 8.1302e-05\n",
      "Epoch 161/500\n",
      "1347/1347 [==============================] - 0s 64us/step - loss: 0.0028 - mean_squared_error: 1.0088e-04\n",
      "Epoch 162/500\n",
      "1347/1347 [==============================] - 0s 63us/step - loss: 0.0027 - mean_squared_error: 7.7968e-05\n",
      "Epoch 163/500\n",
      "1347/1347 [==============================] - 0s 65us/step - loss: 0.0026 - mean_squared_error: 7.2959e-05\n",
      "Epoch 164/500\n",
      "1347/1347 [==============================] - 0s 63us/step - loss: 0.0026 - mean_squared_error: 7.8316e-05\n",
      "Epoch 165/500\n",
      "1347/1347 [==============================] - 0s 64us/step - loss: 0.0026 - mean_squared_error: 7.2784e-05\n",
      "Epoch 166/500\n",
      "1347/1347 [==============================] - 0s 64us/step - loss: 0.0026 - mean_squared_error: 7.3013e-05\n",
      "Epoch 167/500\n",
      "1347/1347 [==============================] - 0s 70us/step - loss: 0.0026 - mean_squared_error: 7.3427e-05\n",
      "Epoch 168/500\n",
      "1347/1347 [==============================] - 0s 70us/step - loss: 0.0025 - mean_squared_error: 7.1891e-05\n",
      "Epoch 169/500\n",
      "1347/1347 [==============================] - 0s 64us/step - loss: 0.0025 - mean_squared_error: 7.1655e-05\n",
      "Epoch 170/500\n",
      "1347/1347 [==============================] - 0s 65us/step - loss: 0.0025 - mean_squared_error: 6.7812e-05\n",
      "Epoch 171/500\n",
      "1347/1347 [==============================] - 0s 64us/step - loss: 0.0025 - mean_squared_error: 6.4458e-05\n",
      "Epoch 172/500\n",
      "1347/1347 [==============================] - 0s 62us/step - loss: 0.0025 - mean_squared_error: 6.5107e-05\n",
      "Epoch 173/500\n",
      "1347/1347 [==============================] - 0s 64us/step - loss: 0.0025 - mean_squared_error: 7.3904e-05\n",
      "Epoch 174/500\n",
      "1347/1347 [==============================] - 0s 66us/step - loss: 0.0024 - mean_squared_error: 6.3752e-05\n",
      "Epoch 175/500\n",
      "1347/1347 [==============================] - 0s 64us/step - loss: 0.0024 - mean_squared_error: 6.3994e-05\n",
      "Epoch 176/500\n",
      "1347/1347 [==============================] - 0s 68us/step - loss: 0.0024 - mean_squared_error: 6.0393e-05\n",
      "Epoch 177/500\n",
      "1347/1347 [==============================] - 0s 66us/step - loss: 0.0024 - mean_squared_error: 5.9165e-05\n",
      "Epoch 178/500\n",
      "1347/1347 [==============================] - 0s 66us/step - loss: 0.0023 - mean_squared_error: 5.9239e-05\n",
      "Epoch 179/500\n",
      "1347/1347 [==============================] - 0s 67us/step - loss: 0.0023 - mean_squared_error: 5.8507e-05\n",
      "Epoch 180/500\n",
      "1347/1347 [==============================] - 0s 74us/step - loss: 0.0023 - mean_squared_error: 5.8111e-05\n",
      "Epoch 181/500\n",
      "1347/1347 [==============================] - 0s 73us/step - loss: 0.0023 - mean_squared_error: 5.6611e-05\n",
      "Epoch 182/500\n",
      "1347/1347 [==============================] - 0s 61us/step - loss: 0.0023 - mean_squared_error: 5.5884e-05\n",
      "Epoch 183/500\n",
      "1347/1347 [==============================] - 0s 64us/step - loss: 0.0022 - mean_squared_error: 5.3954e-05\n",
      "Epoch 184/500\n",
      "1347/1347 [==============================] - 0s 65us/step - loss: 0.0022 - mean_squared_error: 5.4517e-05\n",
      "Epoch 185/500\n",
      "1347/1347 [==============================] - 0s 61us/step - loss: 0.0022 - mean_squared_error: 5.4692e-05\n",
      "Epoch 186/500\n",
      "1347/1347 [==============================] - 0s 57us/step - loss: 0.0022 - mean_squared_error: 5.2648e-05\n",
      "Epoch 187/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 0.0022 - mean_squared_error: 5.1596e-05\n",
      "Epoch 188/500\n",
      "1347/1347 [==============================] - 0s 55us/step - loss: 0.0022 - mean_squared_error: 5.1635e-05\n",
      "Epoch 189/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 0.0022 - mean_squared_error: 5.1463e-05\n",
      "Epoch 190/500\n",
      "1347/1347 [==============================] - 0s 55us/step - loss: 0.0021 - mean_squared_error: 4.9126e-05\n",
      "Epoch 191/500\n",
      "1347/1347 [==============================] - 0s 57us/step - loss: 0.0021 - mean_squared_error: 4.8066e-05\n",
      "Epoch 192/500\n",
      "1347/1347 [==============================] - 0s 55us/step - loss: 0.0021 - mean_squared_error: 4.7640e-05\n",
      "Epoch 193/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 0.0021 - mean_squared_error: 4.8700e-05\n",
      "Epoch 194/500\n",
      "1347/1347 [==============================] - 0s 63us/step - loss: 0.0021 - mean_squared_error: 4.7503e-05\n",
      "Epoch 195/500\n",
      "1347/1347 [==============================] - 0s 64us/step - loss: 0.0021 - mean_squared_error: 4.5681e-05\n",
      "Epoch 196/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 0.0020 - mean_squared_error: 4.7514e-05\n",
      "Epoch 197/500\n",
      "1347/1347 [==============================] - 0s 58us/step - loss: 0.0020 - mean_squared_error: 4.4647e-05\n",
      "Epoch 198/500\n",
      "1347/1347 [==============================] - 0s 67us/step - loss: 0.0020 - mean_squared_error: 4.8860e-05\n",
      "Epoch 199/500\n",
      "1347/1347 [==============================] - 0s 66us/step - loss: 0.0020 - mean_squared_error: 4.2953e-05\n",
      "Epoch 200/500\n",
      "1347/1347 [==============================] - 0s 59us/step - loss: 0.0020 - mean_squared_error: 4.2975e-05\n",
      "Epoch 201/500\n",
      "1347/1347 [==============================] - 0s 55us/step - loss: 0.0020 - mean_squared_error: 4.1766e-05\n",
      "Epoch 202/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 0.0020 - mean_squared_error: 4.3054e-05\n",
      "Epoch 203/500\n",
      "1347/1347 [==============================] - 0s 55us/step - loss: 0.0020 - mean_squared_error: 4.1464e-05\n",
      "Epoch 204/500\n",
      "1347/1347 [==============================] - 0s 57us/step - loss: 0.0019 - mean_squared_error: 4.0681e-05\n",
      "Epoch 205/500\n",
      "1347/1347 [==============================] - 0s 54us/step - loss: 0.0019 - mean_squared_error: 4.1483e-05\n",
      "Epoch 206/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 0.0019 - mean_squared_error: 4.0144e-05\n",
      "Epoch 207/500\n",
      "1347/1347 [==============================] - 0s 53us/step - loss: 0.0019 - mean_squared_error: 4.0079e-05\n",
      "Epoch 208/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1347/1347 [==============================] - 0s 59us/step - loss: 0.0019 - mean_squared_error: 3.9028e-05\n",
      "Epoch 209/500\n",
      "1347/1347 [==============================] - 0s 64us/step - loss: 0.0019 - mean_squared_error: 3.9194e-05\n",
      "Epoch 210/500\n",
      "1347/1347 [==============================] - 0s 61us/step - loss: 0.0019 - mean_squared_error: 3.8077e-05\n",
      "Epoch 211/500\n",
      "1347/1347 [==============================] - 0s 58us/step - loss: 0.0019 - mean_squared_error: 3.9293e-05\n",
      "Epoch 212/500\n",
      "1347/1347 [==============================] - 0s 54us/step - loss: 0.0019 - mean_squared_error: 3.9050e-05\n",
      "Epoch 213/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 0.0018 - mean_squared_error: 3.7537e-05\n",
      "Epoch 214/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 0.0018 - mean_squared_error: 3.6397e-05\n",
      "Epoch 215/500\n",
      "1347/1347 [==============================] - 0s 54us/step - loss: 0.0018 - mean_squared_error: 3.5480e-05\n",
      "Epoch 216/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 0.0018 - mean_squared_error: 3.6581e-05\n",
      "Epoch 217/500\n",
      "1347/1347 [==============================] - 0s 55us/step - loss: 0.0018 - mean_squared_error: 3.3800e-05\n",
      "Epoch 218/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 0.0018 - mean_squared_error: 3.3950e-05\n",
      "Epoch 219/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 0.0017 - mean_squared_error: 3.3485e-05\n",
      "Epoch 220/500\n",
      "1347/1347 [==============================] - 0s 54us/step - loss: 0.0017 - mean_squared_error: 3.3344e-05\n",
      "Epoch 221/500\n",
      "1347/1347 [==============================] - 0s 57us/step - loss: 0.0017 - mean_squared_error: 3.3766e-05\n",
      "Epoch 222/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 0.0017 - mean_squared_error: 3.2497e-05\n",
      "Epoch 223/500\n",
      "1347/1347 [==============================] - 0s 62us/step - loss: 0.0017 - mean_squared_error: 3.1895e-05\n",
      "Epoch 224/500\n",
      "1347/1347 [==============================] - 0s 65us/step - loss: 0.0017 - mean_squared_error: 3.1635e-05\n",
      "Epoch 225/500\n",
      "1347/1347 [==============================] - 0s 58us/step - loss: 0.0017 - mean_squared_error: 3.1838e-05\n",
      "Epoch 226/500\n",
      "1347/1347 [==============================] - 0s 55us/step - loss: 0.0017 - mean_squared_error: 3.1653e-05\n",
      "Epoch 227/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 0.0017 - mean_squared_error: 3.1162e-05\n",
      "Epoch 228/500\n",
      "1347/1347 [==============================] - 0s 53us/step - loss: 0.0017 - mean_squared_error: 3.0894e-05\n",
      "Epoch 229/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 0.0017 - mean_squared_error: 3.1430e-05\n",
      "Epoch 230/500\n",
      "1347/1347 [==============================] - 0s 54us/step - loss: 0.0016 - mean_squared_error: 2.9822e-05\n",
      "Epoch 231/500\n",
      "1347/1347 [==============================] - 0s 57us/step - loss: 0.0016 - mean_squared_error: 2.9334e-05\n",
      "Epoch 232/500\n",
      "1347/1347 [==============================] - 0s 57us/step - loss: 0.0016 - mean_squared_error: 3.0466e-05\n",
      "Epoch 233/500\n",
      "1347/1347 [==============================] - 0s 54us/step - loss: 0.0016 - mean_squared_error: 2.8355e-05\n",
      "Epoch 234/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 0.0016 - mean_squared_error: 2.9307e-05\n",
      "Epoch 235/500\n",
      "1347/1347 [==============================] - 0s 55us/step - loss: 0.0016 - mean_squared_error: 2.8233e-05\n",
      "Epoch 236/500\n",
      "1347/1347 [==============================] - 0s 57us/step - loss: 0.0016 - mean_squared_error: 2.8312e-05\n",
      "Epoch 237/500\n",
      "1347/1347 [==============================] - 0s 58us/step - loss: 0.0016 - mean_squared_error: 2.7612e-05\n",
      "Epoch 238/500\n",
      "1347/1347 [==============================] - 0s 60us/step - loss: 0.0016 - mean_squared_error: 2.7205e-05\n",
      "Epoch 239/500\n",
      "1347/1347 [==============================] - 0s 66us/step - loss: 0.0016 - mean_squared_error: 2.6703e-05\n",
      "Epoch 240/500\n",
      "1347/1347 [==============================] - 0s 58us/step - loss: 0.0015 - mean_squared_error: 2.6717e-05\n",
      "Epoch 241/500\n",
      "1347/1347 [==============================] - 0s 58us/step - loss: 0.0015 - mean_squared_error: 2.6176e-05\n",
      "Epoch 242/500\n",
      "1347/1347 [==============================] - 0s 53us/step - loss: 0.0015 - mean_squared_error: 2.5914e-05\n",
      "Epoch 243/500\n",
      "1347/1347 [==============================] - 0s 57us/step - loss: 0.0015 - mean_squared_error: 2.5881e-05\n",
      "Epoch 244/500\n",
      "1347/1347 [==============================] - 0s 54us/step - loss: 0.0015 - mean_squared_error: 2.6526e-05\n",
      "Epoch 245/500\n",
      "1347/1347 [==============================] - 0s 57us/step - loss: 0.0015 - mean_squared_error: 2.5353e-05\n",
      "Epoch 246/500\n",
      "1347/1347 [==============================] - 0s 54us/step - loss: 0.0015 - mean_squared_error: 2.4682e-05\n",
      "Epoch 247/500\n",
      "1347/1347 [==============================] - 0s 57us/step - loss: 0.0015 - mean_squared_error: 2.5054e-05\n",
      "Epoch 248/500\n",
      "1347/1347 [==============================] - 0s 54us/step - loss: 0.0015 - mean_squared_error: 2.5231e-05\n",
      "Epoch 249/500\n",
      "1347/1347 [==============================] - 0s 58us/step - loss: 0.0015 - mean_squared_error: 2.4402e-05\n",
      "Epoch 250/500\n",
      "1347/1347 [==============================] - 0s 57us/step - loss: 0.0015 - mean_squared_error: 2.4242e-05\n",
      "Epoch 251/500\n",
      "1347/1347 [==============================] - 0s 55us/step - loss: 0.0015 - mean_squared_error: 2.3787e-05\n",
      "Epoch 252/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 0.0015 - mean_squared_error: 2.3623e-05\n",
      "Epoch 253/500\n",
      "1347/1347 [==============================] - 0s 67us/step - loss: 0.0015 - mean_squared_error: 2.6959e-05\n",
      "Epoch 254/500\n",
      "1347/1347 [==============================] - 0s 64us/step - loss: 0.0014 - mean_squared_error: 2.2462e-05\n",
      "Epoch 255/500\n",
      "1347/1347 [==============================] - 0s 69us/step - loss: 0.0014 - mean_squared_error: 2.2433e-05\n",
      "Epoch 256/500\n",
      "1347/1347 [==============================] - 0s 60us/step - loss: 0.0014 - mean_squared_error: 2.2501e-05\n",
      "Epoch 257/500\n",
      "1347/1347 [==============================] - 0s 61us/step - loss: 0.0014 - mean_squared_error: 2.1882e-05\n",
      "Epoch 258/500\n",
      "1347/1347 [==============================] - 0s 61us/step - loss: 0.0014 - mean_squared_error: 2.2052e-05\n",
      "Epoch 259/500\n",
      "1347/1347 [==============================] - 0s 64us/step - loss: 0.0014 - mean_squared_error: 2.2102e-05\n",
      "Epoch 260/500\n",
      "1347/1347 [==============================] - 0s 62us/step - loss: 0.0014 - mean_squared_error: 2.0957e-05\n",
      "Epoch 261/500\n",
      "1347/1347 [==============================] - 0s 61us/step - loss: 0.0014 - mean_squared_error: 2.1038e-05\n",
      "Epoch 262/500\n",
      "1347/1347 [==============================] - 0s 61us/step - loss: 0.0014 - mean_squared_error: 2.1259e-05\n",
      "Epoch 263/500\n",
      "1347/1347 [==============================] - 0s 73us/step - loss: 0.0014 - mean_squared_error: 2.1019e-05\n",
      "Epoch 264/500\n",
      "1347/1347 [==============================] - 0s 58us/step - loss: 0.0014 - mean_squared_error: 2.0888e-05 0s - loss: 0.0014 - mean_squared_error: 2.1910e-\n",
      "Epoch 265/500\n",
      "1347/1347 [==============================] - 0s 57us/step - loss: 0.0014 - mean_squared_error: 2.0449e-05\n",
      "Epoch 266/500\n",
      "1347/1347 [==============================] - 0s 54us/step - loss: 0.0013 - mean_squared_error: 1.9899e-05\n",
      "Epoch 267/500\n",
      "1347/1347 [==============================] - 0s 61us/step - loss: 0.0013 - mean_squared_error: 1.9745e-05\n",
      "Epoch 268/500\n",
      "1347/1347 [==============================] - 0s 69us/step - loss: 0.0013 - mean_squared_error: 1.9904e-05\n",
      "Epoch 269/500\n",
      "1347/1347 [==============================] - 0s 64us/step - loss: 0.0013 - mean_squared_error: 1.9412e-05\n",
      "Epoch 270/500\n",
      "1347/1347 [==============================] - 0s 61us/step - loss: 0.0013 - mean_squared_error: 2.0083e-05\n",
      "Epoch 271/500\n",
      "1347/1347 [==============================] - 0s 59us/step - loss: 0.0013 - mean_squared_error: 1.9034e-05\n",
      "Epoch 272/500\n",
      "1347/1347 [==============================] - 0s 60us/step - loss: 0.0013 - mean_squared_error: 1.9115e-05\n",
      "Epoch 273/500\n",
      "1347/1347 [==============================] - 0s 61us/step - loss: 0.0013 - mean_squared_error: 1.8592e-05\n",
      "Epoch 274/500\n",
      "1347/1347 [==============================] - 0s 59us/step - loss: 0.0013 - mean_squared_error: 1.8481e-05\n",
      "Epoch 275/500\n",
      "1347/1347 [==============================] - 0s 59us/step - loss: 0.0013 - mean_squared_error: 1.8936e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 276/500\n",
      "1347/1347 [==============================] - 0s 58us/step - loss: 0.0013 - mean_squared_error: 1.8854e-05\n",
      "Epoch 277/500\n",
      "1347/1347 [==============================] - 0s 58us/step - loss: 0.0013 - mean_squared_error: 1.8462e-05\n",
      "Epoch 278/500\n",
      "1347/1347 [==============================] - 0s 59us/step - loss: 0.0013 - mean_squared_error: 1.8090e-05\n",
      "Epoch 279/500\n",
      "1347/1347 [==============================] - 0s 57us/step - loss: 0.0013 - mean_squared_error: 1.7633e-05\n",
      "Epoch 280/500\n",
      "1347/1347 [==============================] - 0s 58us/step - loss: 0.0013 - mean_squared_error: 1.8046e-05\n",
      "Epoch 281/500\n",
      "1347/1347 [==============================] - 0s 58us/step - loss: 0.0013 - mean_squared_error: 1.7694e-05\n",
      "Epoch 282/500\n",
      "1347/1347 [==============================] - 0s 58us/step - loss: 0.0013 - mean_squared_error: 1.7275e-05\n",
      "Epoch 283/500\n",
      "1347/1347 [==============================] - 0s 60us/step - loss: 0.0013 - mean_squared_error: 1.7690e-05\n",
      "Epoch 284/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 0.0012 - mean_squared_error: 1.7313e-05\n",
      "Epoch 285/500\n",
      "1347/1347 [==============================] - 0s 57us/step - loss: 0.0012 - mean_squared_error: 1.7278e-05\n",
      "Epoch 286/500\n",
      "1347/1347 [==============================] - 0s 58us/step - loss: 0.0012 - mean_squared_error: 1.6672e-05\n",
      "Epoch 287/500\n",
      "1347/1347 [==============================] - 0s 61us/step - loss: 0.0012 - mean_squared_error: 1.7004e-05\n",
      "Epoch 288/500\n",
      "1347/1347 [==============================] - 0s 62us/step - loss: 0.0012 - mean_squared_error: 1.6499e-05\n",
      "Epoch 289/500\n",
      "1347/1347 [==============================] - 0s 62us/step - loss: 0.0012 - mean_squared_error: 1.7011e-05\n",
      "Epoch 290/500\n",
      "1347/1347 [==============================] - 0s 61us/step - loss: 0.0012 - mean_squared_error: 1.6390e-05\n",
      "Epoch 291/500\n",
      "1347/1347 [==============================] - 0s 62us/step - loss: 0.0012 - mean_squared_error: 1.5848e-05\n",
      "Epoch 292/500\n",
      "1347/1347 [==============================] - 0s 63us/step - loss: 0.0012 - mean_squared_error: 1.6083e-05\n",
      "Epoch 293/500\n",
      "1347/1347 [==============================] - 0s 59us/step - loss: 0.0012 - mean_squared_error: 1.5994e-05\n",
      "Epoch 294/500\n",
      "1347/1347 [==============================] - 0s 58us/step - loss: 0.0012 - mean_squared_error: 1.5675e-05\n",
      "Epoch 295/500\n",
      "1347/1347 [==============================] - 0s 60us/step - loss: 0.0012 - mean_squared_error: 1.5437e-05\n",
      "Epoch 296/500\n",
      "1347/1347 [==============================] - 0s 67us/step - loss: 0.0012 - mean_squared_error: 1.5378e-05\n",
      "Epoch 297/500\n",
      "1347/1347 [==============================] - 0s 70us/step - loss: 0.0012 - mean_squared_error: 1.5319e-05\n",
      "Epoch 298/500\n",
      "1347/1347 [==============================] - 0s 63us/step - loss: 0.0012 - mean_squared_error: 1.5122e-05\n",
      "Epoch 299/500\n",
      "1347/1347 [==============================] - 0s 66us/step - loss: 0.0012 - mean_squared_error: 1.5104e-05\n",
      "Epoch 300/500\n",
      "1347/1347 [==============================] - 0s 59us/step - loss: 0.0012 - mean_squared_error: 1.5000e-05\n",
      "Epoch 301/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 0.0012 - mean_squared_error: 1.4608e-05\n",
      "Epoch 302/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 0.0011 - mean_squared_error: 1.4354e-05\n",
      "Epoch 303/500\n",
      "1347/1347 [==============================] - 0s 58us/step - loss: 0.0011 - mean_squared_error: 1.4556e-05\n",
      "Epoch 304/500\n",
      "1347/1347 [==============================] - 0s 58us/step - loss: 0.0012 - mean_squared_error: 1.6945e-05\n",
      "Epoch 305/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 0.0012 - mean_squared_error: 1.5246e-05\n",
      "Epoch 306/500\n",
      "1347/1347 [==============================] - 0s 58us/step - loss: 0.0011 - mean_squared_error: 1.4208e-05\n",
      "Epoch 307/500\n",
      "1347/1347 [==============================] - 0s 60us/step - loss: 0.0011 - mean_squared_error: 1.4439e-05\n",
      "Epoch 308/500\n",
      "1347/1347 [==============================] - 0s 58us/step - loss: 0.0011 - mean_squared_error: 1.3671e-05\n",
      "Epoch 309/500\n",
      "1347/1347 [==============================] - 0s 63us/step - loss: 0.0011 - mean_squared_error: 1.4322e-05\n",
      "Epoch 310/500\n",
      "1347/1347 [==============================] - 0s 60us/step - loss: 0.0011 - mean_squared_error: 1.3470e-05\n",
      "Epoch 311/500\n",
      "1347/1347 [==============================] - 0s 63us/step - loss: 0.0011 - mean_squared_error: 1.3254e-05\n",
      "Epoch 312/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 0.0011 - mean_squared_error: 1.3055e-05\n",
      "Epoch 313/500\n",
      "1347/1347 [==============================] - ETA: 0s - loss: 0.0010 - mean_squared_error: 1.1570e-05   - 0s 54us/step - loss: 0.0011 - mean_squared_error: 1.3261e-05\n",
      "Epoch 314/500\n",
      "1347/1347 [==============================] - 0s 57us/step - loss: 0.0011 - mean_squared_error: 1.3216e-05\n",
      "Epoch 315/500\n",
      "1347/1347 [==============================] - 0s 54us/step - loss: 0.0011 - mean_squared_error: 1.3158e-05\n",
      "Epoch 316/500\n",
      "1347/1347 [==============================] - 0s 58us/step - loss: 0.0011 - mean_squared_error: 1.3025e-05\n",
      "Epoch 317/500\n",
      "1347/1347 [==============================] - 0s 58us/step - loss: 0.0011 - mean_squared_error: 1.2775e-05\n",
      "Epoch 318/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 0.0011 - mean_squared_error: 1.2937e-05\n",
      "Epoch 319/500\n",
      "1347/1347 [==============================] - 0s 58us/step - loss: 0.0011 - mean_squared_error: 1.2803e-05\n",
      "Epoch 320/500\n",
      "1347/1347 [==============================] - 0s 58us/step - loss: 0.0011 - mean_squared_error: 1.3561e-05\n",
      "Epoch 321/500\n",
      "1347/1347 [==============================] - 0s 58us/step - loss: 0.0011 - mean_squared_error: 1.2624e-05\n",
      "Epoch 322/500\n",
      "1347/1347 [==============================] - 0s 61us/step - loss: 0.0011 - mean_squared_error: 1.2610e-05\n",
      "Epoch 323/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 0.0011 - mean_squared_error: 1.3251e-05\n",
      "Epoch 324/500\n",
      "1347/1347 [==============================] - 0s 61us/step - loss: 0.0010 - mean_squared_error: 1.2371e-05\n",
      "Epoch 325/500\n",
      "1347/1347 [==============================] - 0s 61us/step - loss: 0.0010 - mean_squared_error: 1.2074e-05\n",
      "Epoch 326/500\n",
      "1347/1347 [==============================] - 0s 57us/step - loss: 0.0010 - mean_squared_error: 1.2189e-05\n",
      "Epoch 327/500\n",
      "1347/1347 [==============================] - 0s 60us/step - loss: 0.0010 - mean_squared_error: 1.1564e-05\n",
      "Epoch 328/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 0.0010 - mean_squared_error: 1.1851e-05\n",
      "Epoch 329/500\n",
      "1347/1347 [==============================] - 0s 59us/step - loss: 0.0010 - mean_squared_error: 1.1409e-05\n",
      "Epoch 330/500\n",
      "1347/1347 [==============================] - 0s 58us/step - loss: 0.0010 - mean_squared_error: 1.1694e-05\n",
      "Epoch 331/500\n",
      "1347/1347 [==============================] - 0s 55us/step - loss: 0.0010 - mean_squared_error: 1.1386e-05\n",
      "Epoch 332/500\n",
      "1347/1347 [==============================] - 0s 61us/step - loss: 0.0010 - mean_squared_error: 1.1084e-05\n",
      "Epoch 333/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 0.0010 - mean_squared_error: 1.1111e-05\n",
      "Epoch 334/500\n",
      "1347/1347 [==============================] - 0s 61us/step - loss: 0.0010 - mean_squared_error: 1.1037e-05\n",
      "Epoch 335/500\n",
      "1347/1347 [==============================] - 0s 59us/step - loss: 0.0010 - mean_squared_error: 1.1243e-05\n",
      "Epoch 336/500\n",
      "1347/1347 [==============================] - 0s 55us/step - loss: 9.9862e-04 - mean_squared_error: 1.1158e-05\n",
      "Epoch 337/500\n",
      "1347/1347 [==============================] - 0s 77us/step - loss: 9.9141e-04 - mean_squared_error: 1.0791e-05\n",
      "Epoch 338/500\n",
      "1347/1347 [==============================] - 0s 74us/step - loss: 9.9065e-04 - mean_squared_error: 1.0793e-05\n",
      "Epoch 339/500\n",
      "1347/1347 [==============================] - 0s 70us/step - loss: 9.8357e-04 - mean_squared_error: 1.0578e-05\n",
      "Epoch 340/500\n",
      "1347/1347 [==============================] - 0s 67us/step - loss: 9.8090e-04 - mean_squared_error: 1.0503e-05\n",
      "Epoch 341/500\n",
      "1347/1347 [==============================] - 0s 63us/step - loss: 9.8111e-04 - mean_squared_error: 1.0898e-05\n",
      "Epoch 342/500\n",
      "1347/1347 [==============================] - 0s 66us/step - loss: 9.7488e-04 - mean_squared_error: 1.0686e-05\n",
      "Epoch 343/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1347/1347 [==============================] - 0s 66us/step - loss: 9.7902e-04 - mean_squared_error: 1.0508e-05\n",
      "Epoch 344/500\n",
      "1347/1347 [==============================] - 0s 70us/step - loss: 9.6700e-04 - mean_squared_error: 1.0429e-05\n",
      "Epoch 345/500\n",
      "1347/1347 [==============================] - 0s 67us/step - loss: 9.6093e-04 - mean_squared_error: 1.0076e-05\n",
      "Epoch 346/500\n",
      "1347/1347 [==============================] - 0s 65us/step - loss: 9.6335e-04 - mean_squared_error: 1.0294e-05\n",
      "Epoch 347/500\n",
      "1347/1347 [==============================] - 0s 64us/step - loss: 9.5618e-04 - mean_squared_error: 9.9859e-06\n",
      "Epoch 348/500\n",
      "1347/1347 [==============================] - 0s 64us/step - loss: 9.5185e-04 - mean_squared_error: 9.9427e-06\n",
      "Epoch 349/500\n",
      "1347/1347 [==============================] - 0s 64us/step - loss: 9.5042e-04 - mean_squared_error: 1.0116e-05\n",
      "Epoch 350/500\n",
      "1347/1347 [==============================] - 0s 66us/step - loss: 9.4791e-04 - mean_squared_error: 1.0141e-05\n",
      "Epoch 351/500\n",
      "1347/1347 [==============================] - 0s 70us/step - loss: 9.4639e-04 - mean_squared_error: 1.0010e-05\n",
      "Epoch 352/500\n",
      "1347/1347 [==============================] - 0s 75us/step - loss: 9.3414e-04 - mean_squared_error: 9.8553e-06\n",
      "Epoch 353/500\n",
      "1347/1347 [==============================] - 0s 65us/step - loss: 9.3925e-04 - mean_squared_error: 1.0024e-05\n",
      "Epoch 354/500\n",
      "1347/1347 [==============================] - 0s 66us/step - loss: 9.3225e-04 - mean_squared_error: 9.7748e-06\n",
      "Epoch 355/500\n",
      "1347/1347 [==============================] - 0s 67us/step - loss: 9.2754e-04 - mean_squared_error: 9.5013e-06\n",
      "Epoch 356/500\n",
      "1347/1347 [==============================] - 0s 67us/step - loss: 9.2689e-04 - mean_squared_error: 9.6971e-06\n",
      "Epoch 357/500\n",
      "1347/1347 [==============================] - 0s 67us/step - loss: 9.2010e-04 - mean_squared_error: 9.5812e-06\n",
      "Epoch 358/500\n",
      "1347/1347 [==============================] - 0s 101us/step - loss: 9.1768e-04 - mean_squared_error: 9.3372e-06\n",
      "Epoch 359/500\n",
      "1347/1347 [==============================] - 0s 72us/step - loss: 9.1671e-04 - mean_squared_error: 9.3192e-06\n",
      "Epoch 360/500\n",
      "1347/1347 [==============================] - 0s 69us/step - loss: 9.1230e-04 - mean_squared_error: 9.3397e-06\n",
      "Epoch 361/500\n",
      "1347/1347 [==============================] - 0s 68us/step - loss: 9.6815e-04 - mean_squared_error: 1.1017e-05\n",
      "Epoch 362/500\n",
      "1347/1347 [==============================] - 0s 67us/step - loss: 9.1950e-04 - mean_squared_error: 9.4229e-06\n",
      "Epoch 363/500\n",
      "1347/1347 [==============================] - 0s 72us/step - loss: 9.0825e-04 - mean_squared_error: 9.0256e-06\n",
      "Epoch 364/500\n",
      "1347/1347 [==============================] - 0s 73us/step - loss: 9.0466e-04 - mean_squared_error: 8.9901e-06\n",
      "Epoch 365/500\n",
      "1347/1347 [==============================] - 0s 67us/step - loss: 9.0203e-04 - mean_squared_error: 9.0193e-06\n",
      "Epoch 366/500\n",
      "1347/1347 [==============================] - 0s 68us/step - loss: 8.9532e-04 - mean_squared_error: 8.8294e-06\n",
      "Epoch 367/500\n",
      "1347/1347 [==============================] - 0s 66us/step - loss: 8.9145e-04 - mean_squared_error: 8.7403e-06\n",
      "Epoch 368/500\n",
      "1347/1347 [==============================] - 0s 63us/step - loss: 8.8722e-04 - mean_squared_error: 8.6218e-06\n",
      "Epoch 369/500\n",
      "1347/1347 [==============================] - 0s 64us/step - loss: 8.8293e-04 - mean_squared_error: 8.5448e-06\n",
      "Epoch 370/500\n",
      "1347/1347 [==============================] - 0s 65us/step - loss: 8.8069e-04 - mean_squared_error: 8.5028e-06\n",
      "Epoch 371/500\n",
      "1347/1347 [==============================] - 0s 68us/step - loss: 8.7735e-04 - mean_squared_error: 8.4655e-06\n",
      "Epoch 372/500\n",
      "1347/1347 [==============================] - 0s 71us/step - loss: 8.7575e-04 - mean_squared_error: 8.4711e-06\n",
      "Epoch 373/500\n",
      "1347/1347 [==============================] - 0s 63us/step - loss: 8.7266e-04 - mean_squared_error: 8.4898e-06\n",
      "Epoch 374/500\n",
      "1347/1347 [==============================] - 0s 64us/step - loss: 8.7000e-04 - mean_squared_error: 8.4809e-06\n",
      "Epoch 375/500\n",
      "1347/1347 [==============================] - 0s 62us/step - loss: 8.7186e-04 - mean_squared_error: 8.5853e-06\n",
      "Epoch 376/500\n",
      "1347/1347 [==============================] - 0s 90us/step - loss: 8.6335e-04 - mean_squared_error: 8.3868e-06\n",
      "Epoch 377/500\n",
      "1347/1347 [==============================] - 0s 75us/step - loss: 8.6078e-04 - mean_squared_error: 8.2508e-06\n",
      "Epoch 378/500\n",
      "1347/1347 [==============================] - 0s 67us/step - loss: 8.5800e-04 - mean_squared_error: 8.1662e-06\n",
      "Epoch 379/500\n",
      "1347/1347 [==============================] - 0s 63us/step - loss: 8.5692e-04 - mean_squared_error: 8.2501e-06\n",
      "Epoch 380/500\n",
      "1347/1347 [==============================] - 0s 55us/step - loss: 8.5025e-04 - mean_squared_error: 8.1187e-06\n",
      "Epoch 381/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 8.6153e-04 - mean_squared_error: 8.5079e-06\n",
      "Epoch 382/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 8.4794e-04 - mean_squared_error: 8.0180e-06\n",
      "Epoch 383/500\n",
      "1347/1347 [==============================] - 0s 58us/step - loss: 8.4343e-04 - mean_squared_error: 7.8110e-06\n",
      "Epoch 384/500\n",
      "1347/1347 [==============================] - 0s 54us/step - loss: 8.4104e-04 - mean_squared_error: 7.8142e-06\n",
      "Epoch 385/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 8.3749e-04 - mean_squared_error: 7.7846e-06\n",
      "Epoch 386/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 8.3376e-04 - mean_squared_error: 7.6610e-06\n",
      "Epoch 387/500\n",
      "1347/1347 [==============================] - 0s 55us/step - loss: 8.3169e-04 - mean_squared_error: 7.6268e-06\n",
      "Epoch 388/500\n",
      "1347/1347 [==============================] - 0s 57us/step - loss: 8.2770e-04 - mean_squared_error: 7.6080e-06\n",
      "Epoch 389/500\n",
      "1347/1347 [==============================] - 0s 55us/step - loss: 8.2550e-04 - mean_squared_error: 7.4030e-06\n",
      "Epoch 390/500\n",
      "1347/1347 [==============================] - 0s 62us/step - loss: 8.2355e-04 - mean_squared_error: 7.5860e-06\n",
      "Epoch 391/500\n",
      "1347/1347 [==============================] - 0s 63us/step - loss: 8.2063e-04 - mean_squared_error: 7.4156e-06\n",
      "Epoch 392/500\n",
      "1347/1347 [==============================] - 0s 59us/step - loss: 8.2188e-04 - mean_squared_error: 7.6347e-06\n",
      "Epoch 393/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 8.4586e-04 - mean_squared_error: 8.6490e-06\n",
      "Epoch 394/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 8.2036e-04 - mean_squared_error: 7.3944e-06\n",
      "Epoch 395/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 8.1426e-04 - mean_squared_error: 7.2550e-06\n",
      "Epoch 396/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 8.0869e-04 - mean_squared_error: 7.0340e-06\n",
      "Epoch 397/500\n",
      "1347/1347 [==============================] - 0s 55us/step - loss: 8.0686e-04 - mean_squared_error: 7.1458e-06\n",
      "Epoch 398/500\n",
      "1347/1347 [==============================] - 0s 58us/step - loss: 8.0436e-04 - mean_squared_error: 7.1399e-06\n",
      "Epoch 399/500\n",
      "1347/1347 [==============================] - 0s 54us/step - loss: 7.9991e-04 - mean_squared_error: 7.0809e-06\n",
      "Epoch 400/500\n",
      "1347/1347 [==============================] - 0s 55us/step - loss: 7.9774e-04 - mean_squared_error: 6.9394e-06\n",
      "Epoch 401/500\n",
      "1347/1347 [==============================] - 0s 57us/step - loss: 7.9373e-04 - mean_squared_error: 6.8745e-06\n",
      "Epoch 402/500\n",
      "1347/1347 [==============================] - 0s 66us/step - loss: 7.9261e-04 - mean_squared_error: 6.9181e-06\n",
      "Epoch 403/500\n",
      "1347/1347 [==============================] - 0s 58us/step - loss: 7.9824e-04 - mean_squared_error: 7.1885e-06\n",
      "Epoch 404/500\n",
      "1347/1347 [==============================] - 0s 55us/step - loss: 7.9062e-04 - mean_squared_error: 6.9804e-06\n",
      "Epoch 405/500\n",
      "1347/1347 [==============================] - 0s 61us/step - loss: 7.8624e-04 - mean_squared_error: 6.8437e-06\n",
      "Epoch 406/500\n",
      "1347/1347 [==============================] - 0s 63us/step - loss: 7.8624e-04 - mean_squared_error: 6.8520e-06\n",
      "Epoch 407/500\n",
      "1347/1347 [==============================] - 0s 58us/step - loss: 7.8106e-04 - mean_squared_error: 6.8477e-06\n",
      "Epoch 408/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 7.7795e-04 - mean_squared_error: 6.7272e-06\n",
      "Epoch 409/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1347/1347 [==============================] - 0s 57us/step - loss: 7.7421e-04 - mean_squared_error: 6.6514e-06\n",
      "Epoch 410/500\n",
      "1347/1347 [==============================] - 0s 54us/step - loss: 7.8941e-04 - mean_squared_error: 7.1017e-06\n",
      "Epoch 411/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 7.7439e-04 - mean_squared_error: 6.7107e-06\n",
      "Epoch 412/500\n",
      "1347/1347 [==============================] - 0s 54us/step - loss: 7.6784e-04 - mean_squared_error: 6.4809e-06\n",
      "Epoch 413/500\n",
      "1347/1347 [==============================] - 0s 55us/step - loss: 7.7632e-04 - mean_squared_error: 6.9947e-06\n",
      "Epoch 414/500\n",
      "1347/1347 [==============================] - 0s 58us/step - loss: 7.6384e-04 - mean_squared_error: 6.5678e-06\n",
      "Epoch 415/500\n",
      "1347/1347 [==============================] - 0s 58us/step - loss: 7.6129e-04 - mean_squared_error: 6.4895e-06\n",
      "Epoch 416/500\n",
      "1347/1347 [==============================] - 0s 61us/step - loss: 7.5856e-04 - mean_squared_error: 6.3729e-06\n",
      "Epoch 417/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 7.5794e-04 - mean_squared_error: 6.4102e-06\n",
      "Epoch 418/500\n",
      "1347/1347 [==============================] - 0s 55us/step - loss: 7.5093e-04 - mean_squared_error: 6.2406e-06\n",
      "Epoch 419/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 7.5059e-04 - mean_squared_error: 6.2388e-06\n",
      "Epoch 420/500\n",
      "1347/1347 [==============================] - 0s 61us/step - loss: 7.4739e-04 - mean_squared_error: 6.2546e-06\n",
      "Epoch 421/500\n",
      "1347/1347 [==============================] - 0s 60us/step - loss: 7.4738e-04 - mean_squared_error: 6.2542e-06\n",
      "Epoch 422/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 7.4258e-04 - mean_squared_error: 6.1140e-06\n",
      "Epoch 423/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 7.4218e-04 - mean_squared_error: 6.1628e-06\n",
      "Epoch 424/500\n",
      "1347/1347 [==============================] - 0s 57us/step - loss: 7.4066e-04 - mean_squared_error: 6.1578e-06\n",
      "Epoch 425/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 7.3615e-04 - mean_squared_error: 6.0237e-06\n",
      "Epoch 426/500\n",
      "1347/1347 [==============================] - 0s 55us/step - loss: 7.3444e-04 - mean_squared_error: 5.9882e-06\n",
      "Epoch 427/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 7.3360e-04 - mean_squared_error: 6.0298e-06\n",
      "Epoch 428/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 7.3013e-04 - mean_squared_error: 5.9524e-06\n",
      "Epoch 429/500\n",
      "1347/1347 [==============================] - 0s 57us/step - loss: 7.2913e-04 - mean_squared_error: 5.9413e-06\n",
      "Epoch 430/500\n",
      "1347/1347 [==============================] - 0s 58us/step - loss: 7.2703e-04 - mean_squared_error: 5.9210e-06\n",
      "Epoch 431/500\n",
      "1347/1347 [==============================] - 0s 54us/step - loss: 7.2393e-04 - mean_squared_error: 5.8103e-06\n",
      "Epoch 432/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 7.2286e-04 - mean_squared_error: 5.8432e-06\n",
      "Epoch 433/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 7.1909e-04 - mean_squared_error: 5.7542e-06\n",
      "Epoch 434/500\n",
      "1347/1347 [==============================] - 0s 61us/step - loss: 7.1845e-04 - mean_squared_error: 5.7840e-06\n",
      "Epoch 435/500\n",
      "1347/1347 [==============================] - 0s 66us/step - loss: 7.1538e-04 - mean_squared_error: 5.7123e-06\n",
      "Epoch 436/500\n",
      "1347/1347 [==============================] - 0s 65us/step - loss: 7.1325e-04 - mean_squared_error: 5.7443e-06\n",
      "Epoch 437/500\n",
      "1347/1347 [==============================] - 0s 58us/step - loss: 7.1284e-04 - mean_squared_error: 5.6526e-06\n",
      "Epoch 438/500\n",
      "1347/1347 [==============================] - 0s 57us/step - loss: 7.1655e-04 - mean_squared_error: 5.8956e-06\n",
      "Epoch 439/500\n",
      "1347/1347 [==============================] - 0s 55us/step - loss: 7.0823e-04 - mean_squared_error: 5.6871e-06\n",
      "Epoch 440/500\n",
      "1347/1347 [==============================] - 0s 60us/step - loss: 7.0523e-04 - mean_squared_error: 5.5629e-06\n",
      "Epoch 441/500\n",
      "1347/1347 [==============================] - 0s 57us/step - loss: 7.0557e-04 - mean_squared_error: 5.6369e-06\n",
      "Epoch 442/500\n",
      "1347/1347 [==============================] - 0s 57us/step - loss: 7.0058e-04 - mean_squared_error: 5.5093e-06\n",
      "Epoch 443/500\n",
      "1347/1347 [==============================] - 0s 61us/step - loss: 6.9945e-04 - mean_squared_error: 5.4660e-06\n",
      "Epoch 444/500\n",
      "1347/1347 [==============================] - 0s 61us/step - loss: 6.9815e-04 - mean_squared_error: 5.4643e-06\n",
      "Epoch 445/500\n",
      "1347/1347 [==============================] - 0s 59us/step - loss: 6.9546e-04 - mean_squared_error: 5.4014e-06\n",
      "Epoch 446/500\n",
      "1347/1347 [==============================] - 0s 60us/step - loss: 6.9390e-04 - mean_squared_error: 5.3467e-06\n",
      "Epoch 447/500\n",
      "1347/1347 [==============================] - 0s 109us/step - loss: 6.9146e-04 - mean_squared_error: 5.3607e-06\n",
      "Epoch 448/500\n",
      "1347/1347 [==============================] - 0s 68us/step - loss: 6.9123e-04 - mean_squared_error: 5.4279e-06\n",
      "Epoch 449/500\n",
      "1347/1347 [==============================] - 0s 69us/step - loss: 6.8917e-04 - mean_squared_error: 5.3138e-06\n",
      "Epoch 450/500\n",
      "1347/1347 [==============================] - 0s 67us/step - loss: 6.8832e-04 - mean_squared_error: 5.3244e-06\n",
      "Epoch 451/500\n",
      "1347/1347 [==============================] - 0s 62us/step - loss: 6.8435e-04 - mean_squared_error: 5.2178e-06\n",
      "Epoch 452/500\n",
      "1347/1347 [==============================] - 0s 62us/step - loss: 6.8320e-04 - mean_squared_error: 5.2373e-06\n",
      "Epoch 453/500\n",
      "1347/1347 [==============================] - 0s 68us/step - loss: 6.8106e-04 - mean_squared_error: 5.2670e-06\n",
      "Epoch 454/500\n",
      "1347/1347 [==============================] - 0s 62us/step - loss: 6.7757e-04 - mean_squared_error: 5.1662e-06\n",
      "Epoch 455/500\n",
      "1347/1347 [==============================] - 0s 66us/step - loss: 6.7798e-04 - mean_squared_error: 5.1840e-06\n",
      "Epoch 456/500\n",
      "1347/1347 [==============================] - 0s 64us/step - loss: 6.7528e-04 - mean_squared_error: 5.1120e-06\n",
      "Epoch 457/500\n",
      "1347/1347 [==============================] - 0s 65us/step - loss: 6.7363e-04 - mean_squared_error: 5.0538e-06\n",
      "Epoch 458/500\n",
      "1347/1347 [==============================] - 0s 64us/step - loss: 6.7182e-04 - mean_squared_error: 5.0961e-06\n",
      "Epoch 459/500\n",
      "1347/1347 [==============================] - 0s 64us/step - loss: 6.6945e-04 - mean_squared_error: 5.0816e-06\n",
      "Epoch 460/500\n",
      "1347/1347 [==============================] - 0s 65us/step - loss: 6.6855e-04 - mean_squared_error: 5.0239e-06\n",
      "Epoch 461/500\n",
      "1347/1347 [==============================] - 0s 67us/step - loss: 6.6750e-04 - mean_squared_error: 4.9806e-06\n",
      "Epoch 462/500\n",
      "1347/1347 [==============================] - 0s 69us/step - loss: 6.6648e-04 - mean_squared_error: 5.0176e-06\n",
      "Epoch 463/500\n",
      "1347/1347 [==============================] - 0s 68us/step - loss: 6.6332e-04 - mean_squared_error: 4.9508e-06\n",
      "Epoch 464/500\n",
      "1347/1347 [==============================] - 0s 65us/step - loss: 6.6040e-04 - mean_squared_error: 4.9233e-06\n",
      "Epoch 465/500\n",
      "1347/1347 [==============================] - 0s 65us/step - loss: 6.5790e-04 - mean_squared_error: 4.8429e-06\n",
      "Epoch 466/500\n",
      "1347/1347 [==============================] - 0s 64us/step - loss: 6.5761e-04 - mean_squared_error: 4.8483e-06\n",
      "Epoch 467/500\n",
      "1347/1347 [==============================] - 0s 62us/step - loss: 6.5517e-04 - mean_squared_error: 4.8405e-06\n",
      "Epoch 468/500\n",
      "1347/1347 [==============================] - 0s 64us/step - loss: 6.5393e-04 - mean_squared_error: 4.7942e-06\n",
      "Epoch 469/500\n",
      "1347/1347 [==============================] - 0s 64us/step - loss: 6.5133e-04 - mean_squared_error: 4.7445e-06\n",
      "Epoch 470/500\n",
      "1347/1347 [==============================] - 0s 64us/step - loss: 6.4969e-04 - mean_squared_error: 4.7214e-06\n",
      "Epoch 471/500\n",
      "1347/1347 [==============================] - 0s 64us/step - loss: 6.4868e-04 - mean_squared_error: 4.7407e-06\n",
      "Epoch 472/500\n",
      "1347/1347 [==============================] - 0s 63us/step - loss: 6.4570e-04 - mean_squared_error: 4.6552e-06\n",
      "Epoch 473/500\n",
      "1347/1347 [==============================] - 0s 63us/step - loss: 6.4380e-04 - mean_squared_error: 4.6468e-06\n",
      "Epoch 474/500\n",
      "1347/1347 [==============================] - 0s 69us/step - loss: 6.4421e-04 - mean_squared_error: 4.6680e-06\n",
      "Epoch 475/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1347/1347 [==============================] - 0s 67us/step - loss: 6.4193e-04 - mean_squared_error: 4.6817e-06\n",
      "Epoch 476/500\n",
      "1347/1347 [==============================] - 0s 67us/step - loss: 6.3818e-04 - mean_squared_error: 4.5899e-06\n",
      "Epoch 477/500\n",
      "1347/1347 [==============================] - 0s 64us/step - loss: 6.3806e-04 - mean_squared_error: 4.6370e-06\n",
      "Epoch 478/500\n",
      "1347/1347 [==============================] - 0s 64us/step - loss: 6.3620e-04 - mean_squared_error: 4.5602e-06\n",
      "Epoch 479/500\n",
      "1347/1347 [==============================] - 0s 64us/step - loss: 6.3463e-04 - mean_squared_error: 4.5697e-06\n",
      "Epoch 480/500\n",
      "1347/1347 [==============================] - 0s 64us/step - loss: 6.3327e-04 - mean_squared_error: 4.5029e-06\n",
      "Epoch 481/500\n",
      "1347/1347 [==============================] - 0s 64us/step - loss: 6.3201e-04 - mean_squared_error: 4.4885e-06\n",
      "Epoch 482/500\n",
      "1347/1347 [==============================] - ETA: 0s - loss: 5.8366e-04 - mean_squared_error: 4.2465e- - 0s 63us/step - loss: 6.2929e-04 - mean_squared_error: 4.4557e-06\n",
      "Epoch 483/500\n",
      "1347/1347 [==============================] - 0s 63us/step - loss: 6.2772e-04 - mean_squared_error: 4.4172e-06\n",
      "Epoch 484/500\n",
      "1347/1347 [==============================] - 0s 63us/step - loss: 6.2649e-04 - mean_squared_error: 4.3958e-06\n",
      "Epoch 485/500\n",
      "1347/1347 [==============================] - 0s 62us/step - loss: 6.2535e-04 - mean_squared_error: 4.3976e-06\n",
      "Epoch 486/500\n",
      "1347/1347 [==============================] - 0s 67us/step - loss: 6.2399e-04 - mean_squared_error: 4.4351e-06\n",
      "Epoch 487/500\n",
      "1347/1347 [==============================] - 0s 69us/step - loss: 6.2256e-04 - mean_squared_error: 4.4430e-06\n",
      "Epoch 488/500\n",
      "1347/1347 [==============================] - 0s 69us/step - loss: 6.2146e-04 - mean_squared_error: 4.3410e-06\n",
      "Epoch 489/500\n",
      "1347/1347 [==============================] - 0s 67us/step - loss: 6.1880e-04 - mean_squared_error: 4.3290e-06\n",
      "Epoch 490/500\n",
      "1347/1347 [==============================] - 0s 55us/step - loss: 6.1696e-04 - mean_squared_error: 4.3115e-06\n",
      "Epoch 491/500\n",
      "1347/1347 [==============================] - 0s 54us/step - loss: 6.1432e-04 - mean_squared_error: 4.2324e-06\n",
      "Epoch 492/500\n",
      "1347/1347 [==============================] - 0s 61us/step - loss: 6.1471e-04 - mean_squared_error: 4.2946e-06\n",
      "Epoch 493/500\n",
      "1347/1347 [==============================] - 0s 60us/step - loss: 6.1175e-04 - mean_squared_error: 4.2395e-06\n",
      "Epoch 494/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 6.1076e-04 - mean_squared_error: 4.2230e-06\n",
      "Epoch 495/500\n",
      "1347/1347 [==============================] - 0s 57us/step - loss: 6.1036e-04 - mean_squared_error: 4.1927e-06\n",
      "Epoch 496/500\n",
      "1347/1347 [==============================] - 0s 55us/step - loss: 6.0880e-04 - mean_squared_error: 4.1569e-06\n",
      "Epoch 497/500\n",
      "1347/1347 [==============================] - 0s 58us/step - loss: 6.0689e-04 - mean_squared_error: 4.1304e-06\n",
      "Epoch 498/500\n",
      "1347/1347 [==============================] - 0s 56us/step - loss: 6.0395e-04 - mean_squared_error: 4.0612e-06\n",
      "Epoch 499/500\n",
      "1347/1347 [==============================] - 0s 57us/step - loss: 6.0249e-04 - mean_squared_error: 4.0648e-06\n",
      "Epoch 500/500\n",
      "1347/1347 [==============================] - 0s 58us/step - loss: 6.0335e-04 - mean_squared_error: 4.1664e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1587db021c8>"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['mse'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=500, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({True: 1347})\n",
      "Counter({True: 440, False: 10})\n",
      "1.0 0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "Y_prediction = model.predict(X_train)\n",
    "Y_prediction = Y_prediction.reshape(-1)\n",
    "for i in range(Y_prediction.shape[0]):\n",
    "        Y_prediction[i] = 1 if Y_prediction[i] > 0.5 else 0\n",
    "counter = Counter(list((Y_prediction == y_train).reshape(-1)))\n",
    "print(counter)\n",
    "traing_accuracy = counter[True]/len(y_train)\n",
    "\n",
    "Y_prediction = model.predict(X_test)\n",
    "Y_prediction = Y_prediction.reshape(-1)\n",
    "for i in range(Y_prediction.shape[0]):\n",
    "        Y_prediction[i] = 1 if Y_prediction[i] > 0.5 else 0\n",
    "counter = Counter(list((Y_prediction == y_test).reshape(-1)))\n",
    "print(counter)\n",
    "test_accuracy = counter[True]/len(y_test)\n",
    "\n",
    "print(traing_accuracy, test_accuracy)\n",
    "# print([(yp, yt) for yp, yt in zip(Y_prediction.reshape(-1), y_test)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用Keras尝试单层和多层网络，多层比单层结果好多了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.选做题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations on building your first logistic regression model. It is your time to analyze it further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1 Observe the effect of learning rate on the leraning process.   \n",
    "Hits: plot the learning curve with different learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在学习率是0.001，换成0.01 或0.0001 都难以收敛。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2 Observe the effect of iteration_num on the test accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设置迭代次数为10000时，可以观察到模型的cost会周期性变化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge ! ! !\n",
    "\n",
    "The original data have images labeled 0,1,2,3,4,5,6,7,8,9. In our logistic model, we only detect if the digit in the image is larger or smaller than 5. Now, Let's go for a more challenging problem. Try to use softmax function to build a model to recognize which digit (0,1,2,3,4,5,6,7,8,9) is in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations ! You have completed assigment 4. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
